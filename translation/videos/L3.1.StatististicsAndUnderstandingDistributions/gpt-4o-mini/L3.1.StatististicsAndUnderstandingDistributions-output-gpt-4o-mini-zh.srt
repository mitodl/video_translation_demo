1
00:00:05,053 --> 00:00:06,220
讲师：大家好。

2
00:00:06,220 --> 00:00:07,520
欢迎回来。

3
00:00:07,520 --> 00:00:09,760
在今天的讲座中，我们将讨论

4
00:00:09,760 --> 00:00:14,120
用于数据探索和分析的统计学。

5
00:00:14,120 --> 00:00:16,880
让我们先从一个简单的问题开始。

6
00:00:16,880 --> 00:00:18,920
什么是统计学？

7
00:00:18,920 --> 00:00:22,680
正式来说，统计学是数学的一个分支，专注于

8
00:00:22,680 --> 00:00:25,540
收集、分析、解释，

9
00:00:25,540 --> 00:00:29,920
和呈现数据，以提取洞见并支持

10
00:00:29,920 --> 00:00:31,720
更好的决策。

11
00:00:31,720 --> 00:00:36,360
在本讲座中，我们将重点关注描述性统计，它是

12
00:00:36,360 --> 00:00:39,120
帮助我们总结和可视化数据的方法，

13
00:00:39,120 --> 00:00:42,480
以揭示模式和趋势。

14
00:00:42,480 --> 00:00:45,040
让我们从一个例子开始。

15
00:00:45,040 --> 00:00:48,400
假设我们想研究

16
00:00:48,400 --> 00:00:51,560
在环球人工智能（Universal AI）注册的学生的身高。

17
00:00:51,560 --> 00:00:56,720
我们不测量每一个在UAI的学生的身高，

18
00:00:56,720 --> 00:00:58,400
而是采取一个样本——

19
00:00:58,400 --> 00:01:02,650
例如，随机选择100名学生。

20
00:01:02,650 --> 00:01:07,730
这给我们提供了100个身高值的数据集。

21
00:01:07,730 --> 00:01:11,090
现在我们可以开始可视化这些数据，

22
00:01:11,090 --> 00:01:15,370
例如，通过并排绘制所有被抽样学生的身高。

23
00:01:15,370 --> 00:01:17,690
当然，我们可以对数值进行排序，以识别

24
00:01:17,690 --> 00:01:20,770
趋势，即大多数学生的身高相似。

25
00:01:20,770 --> 00:01:26,050
那么，典型学生的身高是多少呢？

26
00:01:26,050 --> 00:01:29,810
有三种常见的方法来描述这一点。

27
00:01:29,810 --> 00:01:33,650
我们可以计算算术平均身高，即均值，

28
00:01:33,650 --> 00:01:38,350
为65英寸。

29
00:01:38,350 --> 00:01:41,290
接下来，我们可以找到中位数，它

30
00:01:41,290 --> 00:01:43,770
代表排序后数据的中间值。

31
00:01:43,770 --> 00:01:47,890
也就是说，有50名学生比这个值矮，50名学生

32
00:01:47,890 --> 00:01:52,530
比这个值高。

33
00:01:52,530 --> 00:01:55,530
最后，我们还可以确定众数，它

34
00:01:55,530 --> 00:01:58,890
是出现频率最高的值。

35
00:01:58,890 --> 00:02:02,410
我们可以将这些身高分组到大小相等的箱中，并计算

36
00:02:02,410 --> 00:02:07,070
有多少学生落入每个箱中。

37
00:02:07,070 --> 00:02:10,389
这个计数和分箱的过程

38
00:02:10,389 --> 00:02:12,750
是用于探索分布的可视化技术的基础。

39
00:02:12,750 --> 00:02:15,870
在这里，我们可以看到大多数学生身高的集中位置，

40
00:02:15,870 --> 00:02:18,990
以及它们在范围上的分布情况。

41
00:02:18,990 --> 00:02:22,790
少数个体相对较高，

42
00:02:22,790 --> 00:02:26,670
但大多数身高集中在中间。

43
00:02:26,670 --> 00:02:29,210
现在，我们可以不再使用单个点，

44
00:02:29,210 --> 00:02:33,390
而使用柱状图来创建直方图。

45
00:02:33,390 --> 00:02:36,370
直方图显示每个箱中值的出现频率，

46
00:02:36,370 --> 00:02:41,670
或者在我们的例子中，身高范围。

47
00:02:41,670 --> 00:02:46,390
这为我们的样本分布提供了清晰的图像，

48
00:02:46,390 --> 00:02:49,910
显示大多数学生的位置以及其余学生的分布情况。

49
00:02:49,910 --> 00:02:54,910
我们可以更改箱的大小——

50
00:02:54,910 --> 00:03:00,190
积分大小——以查看数据中可见的

51
00:03:00,190 --> 00:03:03,230
变异性有多大。

52
00:03:03,230 --> 00:03:06,040
较小的箱大小在更高细粒度上显示变异，

53
00:03:06,040 --> 00:03:09,120
而较大的箱大小

54
00:03:09,120 --> 00:03:11,600
则减少可见细节。

55
00:03:11,600 --> 00:03:15,880
所以如果箱太小，结果

56
00:03:15,880 --> 00:03:18,200
可能会显得嘈杂，而如果箱太大，

57
00:03:18,200 --> 00:03:22,120
则分布可能会变得过于简单化。

58
00:03:22,120 --> 00:03:26,020
我们还可以使用核密度估计（Kernel Density Estimation，KDE）

59
00:03:26,020 --> 00:03:30,080
来呈现数据，它提供了一个平滑的替代方案

60
00:03:30,080 --> 00:03:34,920
给传统的直方图。

61
00:03:34,920 --> 00:03:39,080
与直方图不同，KDE不依赖于箱的大小，

62
00:03:39,080 --> 00:03:41,760
并提供更清晰的数据分布形状的可视化。

63
00:03:41,760 --> 00:03:46,920
另一种替代方案是小提琴图，它是一个镜像的KDE。

64
00:03:46,920 --> 00:03:50,720
它对于比较两个分布非常有用，

65
00:03:50,720 --> 00:03:53,240
例如我们例子中男性和女性学生身高的分布。

66
00:03:53,240 --> 00:03:59,440
说到数据形状，偏度是一个有用的测量指标，

67
00:03:59,440 --> 00:04:03,120
它捕捉了数据分布的非对称性或倾斜度。

68
00:04:03,120 --> 00:04:06,260
它帮助我们理解数据是否存在偏向或在分布的一个

69
00:04:06,260 --> 00:04:09,220
侧面。

70
00:04:09,220 --> 00:04:13,780
例如，如果点在中心周围均匀

71
00:04:13,780 --> 00:04:19,899
分布，数据

72
00:04:19,899 --> 00:04:23,940
是对称的，没有偏斜。

73
00:04:23,940 --> 00:04:25,980
如果大多数数据点聚集在左侧，

74
00:04:25,980 --> 00:04:29,020
右侧有一个长尾，我们称之为正偏。

75
00:04:29,020 --> 00:04:31,380
如果大部分点聚集在右侧，

76
00:04:31,380 --> 00:04:34,300
左侧有一个长尾，则称为负偏。

77
00:04:34,300 --> 00:04:37,740
在一个完全对称的分布中，

78
00:04:37,740 --> 00:04:43,020
均值、中位数和众数是相同的。

79
00:04:43,020 --> 00:04:45,980
然而，在非对称或偏斜分布中，

80
00:04:45,980 --> 00:04:50,260
这三个测量值有所不同。

81
00:04:50,260 --> 00:04:52,980
让我们谈谈离群值。

82
00:04:52,980 --> 00:04:57,300
离群值是在我们的数据集中异常高或异常低的值。

83
00:04:57,300 --> 00:05:01,300
虽然在很多情况下，离群值是可以预期的，

84
00:05:01,300 --> 00:05:04,500
但它们也可能因错误而发生。

85
00:05:04,500 --> 00:05:07,590
例如，假设我们在进行

86
00:05:07,590 --> 00:05:13,710
学生身高的研究，要求学生

87
00:05:13,710 --> 00:05:17,050
报告自己的身高，而其中一名学生

88
00:05:17,050 --> 00:05:19,670
玩笑地报告他的身高与埃菲尔铁塔一样高。

89
00:05:19,670 --> 00:05:22,830
现在，当我们绘制结果时，直方图

90
00:05:22,830 --> 00:05:26,190
可能看起来像这样。

91
00:05:26,190 --> 00:05:29,390
我们的均值现在被扭曲了。

92
00:05:29,390 --> 00:05:34,630
它上升到超过190英寸。

93
00:05:34,630 --> 00:05:37,230
这表明一个离群值是如何严重影响均值的。

94
00:05:37,230 --> 00:05:39,590
然而，中位数保持在大约65英寸，

95
00:05:39,590 --> 00:05:41,650
反映了数据的真实集中趋势。

96
00:06:00,630 --> 00:06:05,030
当我们检查数据集时，我们会发现这个极高的

97
00:06:05,030 --> 00:06:08,290
数值显然是错误的。

98
00:06:08,290 --> 00:06:12,730
我们可以安全地将其删除，以便有效分析我们的数据。

99
00:06:12,730 --> 00:06:16,330
这就是为什么在进行分析或得出结论之前，始终重要地视觉检查

100
00:06:16,330 --> 00:06:21,250
您的数据。

101
00:06:21,250 --> 00:06:24,290
确保一切都说得通。

102
00:06:24,290 --> 00:06:27,850
所以回到我们的描述性统计，

103
00:06:27,850 --> 00:06:32,370
当数据是对称时，均值是合适的选择。

104
00:06:32,370 --> 00:06:34,650
当存在异常值时，中位数特别有用，

105
00:06:34,650 --> 00:06:37,530
因为它

106
00:06:37,530 --> 00:06:40,570
对极端值更为稳健，

107
00:06:40,570 --> 00:06:42,450
就像我们刚才看到的那个。

108
00:06:42,450 --> 00:06:44,610
最后，众数通常用于

109
00:06:44,610 --> 00:06:48,690
分类数据，它表示出现频率最高的

110
00:06:48,690 --> 00:06:51,450
类别。

111
00:06:51,450 --> 00:06:55,370
那么我们来谈谈方差和标准差。

112
00:06:55,370 --> 00:06:59,850
方差和标准差是描述连续数据集中值分散程度的两种最常见方法。

113
00:06:59,850 --> 00:07:03,690
样本方差是样本均值的平方差之和

114
00:07:03,690 --> 00:07:05,250
除以n减1，

115
00:07:05,250 --> 00:07:09,340
其中n是样本大小。

116
00:07:09,340 --> 00:07:13,620
标准差是该方差的平方根。

117
00:07:13,620 --> 00:07:15,900
这两者都量化了个体值

118
00:07:15,900 --> 00:07:20,540
与均值的偏差程度。

119
00:07:20,540 --> 00:07:24,460
为什么标准差很重要？

120
00:07:24,460 --> 00:07:27,340
标准差显示数据点围绕均值的分散程度。

121
00:07:27,340 --> 00:07:30,300
它帮助我们理解数据的一致性。

122
00:07:30,300 --> 00:07:34,060
较小的值意味着数据紧密聚集，

123
00:07:34,060 --> 00:07:36,260
而较大的值则表示更大的分散和更多的

124
00:07:36,260 --> 00:07:40,620
变异。

125
00:07:40,620 --> 00:07:44,340
它显示数据点离均值的平均距离。

126
00:07:44,340 --> 00:07:48,300
在正态分布中，有一些特别有趣的事情发生。

127
00:07:48,300 --> 00:07:50,220
大约68%的数据落在均值的一个标准差内——

128
00:07:50,220 --> 00:07:56,300
也就是说，在均值减去一个标准差

129
00:07:56,300 --> 00:07:59,380
和均值加上一个标准差之间。

130
00:07:59,380 --> 00:08:01,540
此外，如果我们将其扩展到均值减去两个

131
00:08:01,540 --> 00:08:07,380
标准差和均值加上两个标准差，

132
00:08:07,380 --> 00:08:09,200
我们将包括95%的样本。

133
00:08:09,200 --> 00:08:13,840
最后，当我们查看均值减去三个

134
00:08:13,840 --> 00:08:18,240
标准差到均值加上三个标准差的范围时，

135
00:08:18,240 --> 00:08:23,200
这个范围将包含几乎所有

136
00:08:23,200 --> 00:08:28,360
样本，或大约99.7%。

137
00:08:28,360 --> 00:08:33,360
这被称为经验法则，或68-95-99.7法则，

138
00:08:33,360 --> 00:08:38,200
并且它只适用于正态分布。

139
00:08:38,200 --> 00:08:43,400
我们还来谈谈分位数和百分位数。

140
00:08:43,400 --> 00:08:45,640
分位数是将数据集

141
00:08:45,640 --> 00:08:51,320
划分为相等大小区间的值。

142
00:08:51,320 --> 00:08:59,640
例如，四分位数将数据分成四个相等的部分，

143
00:08:59,640 --> 00:09:05,200
以便每个部分大约包含相同数量的数据点。

144
00:09:05,200 --> 00:09:09,650
另一方面，百分位数指的是值在数据集中的位置。

145
00:09:09,650 --> 00:09:13,690
例如，假设我们有100名学生，

146
00:09:13,690 --> 00:09:17,090
如果我们将他们划分为四分位数，

147
00:09:17,090 --> 00:09:22,930
那么每个四分位数中将有25名学生。

148
00:09:22,930 --> 00:09:27,490
然后我们可以使用百分位数来引用这些数据点，

149
00:09:27,490 --> 00:09:29,530
它们表示一个值在数据集中的排名位置。

150
00:09:29,530 --> 00:09:34,130
箱线图是一个重要的可视化工具，

151
00:09:34,130 --> 00:09:37,410
因为它总结了五个关键统计数据。

152
00:09:37,410 --> 00:09:41,210
这里我们可以看到第一个四分位数，

153
00:09:41,210 --> 00:09:44,410
它对应于第25百分位数，

154
00:09:44,410 --> 00:09:49,130
这意味着25%的数据值低于这一点。

155
00:09:49,130 --> 00:09:54,810
中位数，即第二个四分位数，

156
00:09:54,810 --> 00:09:57,090
或第50百分位数，表示一半的数据

157
00:09:57,090 --> 00:10:01,010
低于该值，一半高于该值。

158
00:10:01,010 --> 00:10:04,450
第三个四分位数，即第75百分位数，

159
00:10:04,450 --> 00:10:08,990
意味着75%的数据低于该值，25%

160
00:10:08,990 --> 00:10:12,510
高于该值。

161
00:10:12,510 --> 00:10:16,550
作为第四和第五个关键统计数据，

162
00:10:16,550 --> 00:10:23,790
我们还可以看到排除异常值的最小值和最大值。

163
00:10:23,790 --> 00:10:27,230
因此，它还帮助我们可视化中心、扩散、

164
00:10:27,230 --> 00:10:32,230
以及作为点存在的潜在异常值。

