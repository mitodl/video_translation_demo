1
00:00:05,053 --> 00:00:06,220
講師：みなさん、こんにちは。

2
00:00:06,220 --> 00:00:07,520
おかえりなさい。

3
00:00:07,520 --> 00:00:09,760
本日の講義では、

4
00:00:09,760 --> 00:00:14,120
データ探索とアナリティクスのための統計についてお話しします。

5
00:00:14,120 --> 00:00:16,880
まずは簡単な質問から始めましょう。

6
00:00:16,880 --> 00:00:18,920
統計とは何でしょうか。

7
00:00:18,920 --> 00:00:22,680
形式的には、統計とは数学の一分野で、

8
00:00:22,680 --> 00:00:25,540
洞察を導き出し、より良い意思決定を支援するためにデータを収集・分析・解釈・提示することに焦点を当てたものです。

9
00:00:25,540 --> 00:00:29,920
そしてデータを提示し、洞察を引き出し、意思決定を支援することに焦点を当てたものです。

10
00:00:29,920 --> 00:00:31,720
より良い意思決定のために。

11
00:00:31,720 --> 00:00:36,360
この講義では、記述統計に焦点を当てます。つまり、

12
00:00:36,360 --> 00:00:39,120
データを要約し可視化して、

13
00:00:39,120 --> 00:00:42,480
パターンや傾向を明らかにする方法です。

14
00:00:42,480 --> 00:00:45,040
例から始めましょう。

15
00:00:45,040 --> 00:00:48,400
Universal AI に在籍する学生の身長を

16
00:00:48,400 --> 00:00:51,560
調べたいとします。

17
00:00:51,560 --> 00:00:56,720
UAI の全ての学生の身長を一人残らず測る代わりに、

18
00:00:56,720 --> 00:00:58,400
サンプルを取ります――

19
00:00:58,400 --> 00:01:02,650
例えば、無作為に選んだ100人の学生です。

20
00:01:02,650 --> 00:01:07,730
これで100個の身長値からなるデータセットが得られます。

21
00:01:07,730 --> 00:01:11,090
ここからこのデータを可視化し始められます。

22
00:01:11,090 --> 00:01:15,370
例えば、抽出した全学生の身長を

23
00:01:15,370 --> 00:01:17,690
横並びにプロットする、といった具合です。

24
00:01:17,690 --> 00:01:20,770
もちろん、値を並べ替えて

25
00:01:20,770 --> 00:01:26,050
傾向を見つけることができ、つまりほとんどの学生の身長は近いということがわかります。

26
00:01:26,050 --> 00:01:29,810
では、典型的な学生の身長はどれくらいでしょうか。

27
00:01:29,810 --> 00:01:33,650
それを表す一般的な方法は3つあります。

28
00:01:33,650 --> 00:01:38,350
算術平均である平均身長を計算できます。

29
00:01:38,350 --> 00:01:41,290
それが65インチです。

30
00:01:41,290 --> 00:01:43,770
次に、中央値を求めます。中央値は

31
00:01:43,770 --> 00:01:47,890
データを並べ替えたときの真ん中の値を表します。

32
00:01:47,890 --> 00:01:52,530
つまり、この値より低い学生が50人、

33
00:01:52,530 --> 00:01:55,530
高い学生が50人いるということです。

34
00:01:55,530 --> 00:01:58,890
最後に、最頻値も特定できます。

35
00:01:58,890 --> 00:02:02,410
最も頻繁に現れる値のことです。

36
00:02:02,410 --> 00:02:07,070
これらの身長を等しい幅のビンに分け、各ビンに

37
00:02:07,070 --> 00:02:10,389
何人入るかを数えることができます。

38
00:02:10,389 --> 00:02:12,750
このカウントとビニングの処理は、

39
00:02:12,750 --> 00:02:15,870
分布を探索するために使われる可視化手法の

40
00:02:15,870 --> 00:02:18,990
基礎となります。

41
00:02:18,990 --> 00:02:22,790
ここでは、学生の身長の大半がどこに集中しているか、

42
00:02:22,790 --> 00:02:26,670
そして範囲全体にどう広がっているかがわかります。

43
00:02:26,670 --> 00:02:29,210
一部には比較的背の高い人もいますが、

44
00:02:29,210 --> 00:02:33,390
ほとんどの身長は中央付近に集まっています。

45
00:02:33,390 --> 00:02:36,370
今度は、個々の点の代わりに、

46
00:02:36,370 --> 00:02:41,670
棒グラフを使ってヒストグラムを作ることができます。

47
00:02:41,670 --> 00:02:46,390
ヒストグラムは、各ビンで値がどれだけ頻繁に現れるか、

48
00:02:46,390 --> 00:02:49,910
つまり今回の例では身長の範囲ごとの頻度を示します。

49
00:02:49,910 --> 00:02:54,910
これにより、サンプルの分布がどのようになっているか、

50
00:02:54,910 --> 00:03:00,190
どこに学生が多く、残りがどう広がっているかが明確になります。

51
00:03:00,190 --> 00:03:03,230
ビンの幅――

52
00:03:03,230 --> 00:03:06,040
区切りの幅――を変えて、

53
00:03:06,040 --> 00:03:09,120
データにどれだけの変動が見えるかを確認できます。

54
00:03:09,120 --> 00:03:11,600
ビン幅を小さくすると、

55
00:03:11,600 --> 00:03:15,880
より高い粒度で変動が見えますが、ビン幅を大きくすると

56
00:03:15,880 --> 00:03:18,200
見える詳細は減ります。

57
00:03:18,200 --> 00:03:22,120
したがって、ビンが小さすぎると結果は

58
00:03:22,120 --> 00:03:26,020
ノイズが多くなり、逆に大きすぎると

59
00:03:26,020 --> 00:03:30,080
分布が単純化されすぎてしまいます。

60
00:03:30,080 --> 00:03:34,920
また、カーネル密度推定（Kernel Density Estimation）、

61
00:03:34,920 --> 00:03:39,080
すなわち KDE を用いてデータを提示することもできます。これは

62
00:03:39,080 --> 00:03:41,760
従来のヒストグラムに対する滑らかな代替表現です。

63
00:03:41,760 --> 00:03:46,920
ヒストグラムと異なり、KDE はビン幅に依存せず、

64
00:03:46,920 --> 00:03:50,720
データ分布の形状を

65
00:03:50,720 --> 00:03:53,240
より明瞭に可視化します。

66
00:03:53,240 --> 00:03:59,440
別の選択肢としてはバイオリンプロットがあります。これは KDE を左右対称に映したものです。

67
00:03:59,440 --> 00:04:03,120
2つの分布を比較するのに有用で、

68
00:04:03,120 --> 00:04:06,260
今回の例で言えば、男子学生と女子学生の

69
00:04:06,260 --> 00:04:09,220
身長の分布などが挙げられます。

70
00:04:09,220 --> 00:04:13,780
データの形状といえば、歪度（スキューネス）は有用な尺度で、

71
00:04:13,780 --> 00:04:19,899
データ分布の非対称性、すなわち傾きを捉えます。

72
00:04:19,899 --> 00:04:23,940
データが偏っているか、分布のどちらか一方に寄っているかを

73
00:04:23,940 --> 00:04:25,980
理解するのに役立ちます。

74
00:04:25,980 --> 00:04:29,020
例えば、点が中心の周りに均等に

75
00:04:29,020 --> 00:04:31,380
分布している場合、そのデータは

76
00:04:31,380 --> 00:04:34,300
対称で、歪みはありません。

77
00:04:34,300 --> 00:04:37,740
もしデータ点の大半が左側に集まり、

78
00:04:37,740 --> 00:04:43,020
右側に長い裾があるなら、これは正の歪みと呼びます。

79
00:04:43,020 --> 00:04:45,980
データ点の大半が右側に集まり、

80
00:04:45,980 --> 00:04:50,260
左側に長い裾があるなら、これは負の歪みです。

81
00:04:50,260 --> 00:04:52,980
完全に対称な分布では、

82
00:04:52,980 --> 00:04:57,300
平均、中央値、最頻値は一致します。

83
00:04:57,300 --> 00:05:01,300
しかし、非対称、すなわち歪んだ分布では、

84
00:05:01,300 --> 00:05:04,500
この3つの指標は異なります。

85
00:05:04,500 --> 00:05:07,590
外れ値について話しましょう。

86
00:05:07,590 --> 00:05:13,710
外れ値とは、データセットの中で異常に高い、あるいは低い値のことです。

87
00:05:13,710 --> 00:05:17,050
多くの場合、外れ値は想定されますが、

88
00:05:17,050 --> 00:05:19,670
エラーによって発生することもあります。

89
00:05:19,670 --> 00:05:22,830
例えば、学生の身長に関する

90
00:05:22,830 --> 00:05:26,190
調査を自己申告で行っていて、ある学生が

91
00:05:26,190 --> 00:05:29,390
冗談で自分の身長を

92
00:05:29,390 --> 00:05:34,630
エッフェル塔の高さだと申告したとします。

93
00:05:34,630 --> 00:05:37,230
すると、結果をプロットしたとき、ヒストグラムは

94
00:05:37,230 --> 00:05:39,590
このような形になるかもしれません。

95
00:05:39,590 --> 00:05:41,650
平均が歪められてしまいました。

96
00:05:41,650 --> 00:05:45,470
190インチを超えるまで上がっています。

97
00:05:45,470 --> 00:05:51,550
これは、たった1つの外れ値が平均にいかに大きく影響するかを示しています。

98
00:05:51,550 --> 00:05:56,230
しかし、中央値はおよそ65インチのままで、

99
00:05:56,230 --> 00:06:00,630
データの真の中心傾向を反映しています。

100
00:06:00,630 --> 00:06:05,030
このデータセットを精査すると、この極端に高い

101
00:06:05,030 --> 00:06:08,290
値は明らかに誤りであることがわかります。

102
00:06:08,290 --> 00:06:12,730
データを効果的に分析するために、これは安全に除去できます。

103
00:06:12,730 --> 00:06:16,330
これが、常に視覚的に検査することが重要な理由です。

104
00:06:16,330 --> 00:06:21,250
分析を行ったり結論を導いたりする前に、データを。

105
00:06:21,250 --> 00:06:24,290
すべてが理にかなっていることを確認しましょう。

106
00:06:24,290 --> 00:06:27,850
では記述統計に戻りますが、

107
00:06:27,850 --> 00:06:32,370
データが対称的なときは平均が適切です。

108
00:06:32,370 --> 00:06:34,650
中央値は特に有用で、

109
00:06:34,650 --> 00:06:37,530
外れ値が存在するときには、

110
00:06:37,530 --> 00:06:40,570
極端な値に対してより頑健だからです。

111
00:06:40,570 --> 00:06:42,450
ちょうど今見たようなものに対して。

112
00:06:42,450 --> 00:06:44,610
最後に、最頻値は一般的に

113
00:06:44,610 --> 00:06:48,690
カテゴリカルデータで用いられ、最も頻繁に

114
00:06:48,690 --> 00:06:51,450
出現するカテゴリを表します。

115
00:06:51,450 --> 00:06:55,370
では、分散と標準偏差について話しましょう。

116
00:06:55,370 --> 00:06:59,850
分散と標準偏差は、

117
00:06:59,850 --> 00:07:03,690
連続データの値の散らばり具合を記述する

118
00:07:03,690 --> 00:07:05,250
最も一般的な2つの方法です。

119
00:07:05,250 --> 00:07:09,340
標本分散は、標本平均からの偏差の二乗和を

120
00:07:09,340 --> 00:07:13,620
nマイナス1で割ったものです。

121
00:07:13,620 --> 00:07:15,900
ここで、nは標本サイズです。

122
00:07:15,900 --> 00:07:20,540
標準偏差はこの分散の平方根です。

123
00:07:20,540 --> 00:07:24,460
これらはいずれも、個々の値が

124
00:07:24,460 --> 00:07:27,340
平均からどれだけ逸脱しているかを定量化します。

125
00:07:27,340 --> 00:07:30,300
なぜ標準偏差が重要なのでしょうか。

126
00:07:30,300 --> 00:07:34,060
標準偏差は、データ点が平均のまわりに

127
00:07:34,060 --> 00:07:36,260
どの程度散らばっているかを示します。

128
00:07:36,260 --> 00:07:40,620
データの一貫性を理解するのに役立ちます。

129
00:07:40,620 --> 00:07:44,340
値が小さいほどデータは密にまとまり、

130
00:07:44,340 --> 00:07:48,300
値が大きいほど散らばりが大きく、

131
00:07:48,300 --> 00:07:50,220
変動が大きいことを示します。

132
00:07:50,220 --> 00:07:56,300
データ点が平均からどれだけ離れているかの平均的な距離を示します。

133
00:07:56,300 --> 00:07:59,380
正規分布では、特に

134
00:07:59,380 --> 00:08:01,540
興味深いことが起こります。

135
00:08:01,540 --> 00:08:07,380
データのおよそ68%が平均から1標準偏差の範囲内に

136
00:08:07,380 --> 00:08:09,200
収まります——

137
00:08:09,200 --> 00:08:13,840
つまり、平均マイナス1標準偏差と

138
00:08:13,840 --> 00:08:18,240
平均プラス1標準偏差の間です。

139
00:08:18,240 --> 00:08:23,200
さらに、これを平均マイナス2

140
00:08:23,200 --> 00:08:28,360
標準偏差と平均プラス2標準偏差に広げると、

141
00:08:28,360 --> 00:08:33,360
標本の95%が含まれます。

142
00:08:33,360 --> 00:08:38,200
最後に、平均マイナス3

143
00:08:38,200 --> 00:08:43,400
標準偏差から平均プラス3標準偏差までの範囲を見ると、

144
00:08:43,400 --> 00:08:45,640
その範囲にはほとんどすべて

145
00:08:45,640 --> 00:08:51,320
の標本が含まれ、約99.7%となります。

146
00:08:51,320 --> 00:08:59,640
これは経験則、あるいは68-95-99.7則として知られており、

147
00:08:59,640 --> 00:09:05,200
正規分布にのみ適用されます。

148
00:09:05,200 --> 00:09:09,650
分位点とパーセンタイルについても話しましょう。

149
00:09:09,650 --> 00:09:13,690
分位点は、データセットを

150
00:09:13,690 --> 00:09:17,090
等しい大きさの区間に分割する値です。

151
00:09:17,090 --> 00:09:22,930
例えば四分位点は、データを4つの等しい部分に分割し、

152
00:09:22,930 --> 00:09:27,490
それぞれの部分にほぼ同じ数の

153
00:09:27,490 --> 00:09:29,530
データ点が含まれるようにします。

154
00:09:29,530 --> 00:09:34,130
一方パーセンタイルは、データセット内での値の

155
00:09:34,130 --> 00:09:37,410
位置を指します。

156
00:09:37,410 --> 00:09:41,210
例えば、学生が100人いるとして、

157
00:09:41,210 --> 00:09:44,410
それらを四分位に分けると、

158
00:09:44,410 --> 00:09:49,130
各四分位に25人ずつ入ります。

159
00:09:49,130 --> 00:09:54,810
その後、これらのデータ点をパーセンタイルで参照でき、

160
00:09:54,810 --> 00:09:57,090
それはデータセット内での値の順位上の位置を

161
00:09:57,090 --> 00:10:01,010
表します。

162
00:10:01,010 --> 00:10:04,450
箱ひげ図は重要な可視化ツールで、

163
00:10:04,450 --> 00:10:08,990
5つの主要な統計量を要約するからです。

164
00:10:08,990 --> 00:10:12,510
ここでは第1四分位点が見られ、

165
00:10:12,510 --> 00:10:16,550
これは第25パーセンタイルに相当し、

166
00:10:16,550 --> 00:10:23,790
データ値の25%がこの点より下にあることを意味します。

167
00:10:23,790 --> 00:10:27,230
第2四分位点である中央値、

168
00:10:27,230 --> 00:10:32,230
すなわち第50パーセンタイルは、データの半分が

169
00:10:32,230 --> 00:10:37,470
その値より下に、残りの半分が上にあることを示します。

170
00:10:37,470 --> 00:10:42,350
第3四分位点は第75パーセンタイルで、

171
00:10:42,350 --> 00:10:48,470
データの75%がこの値より下、25%が

172
00:10:48,470 --> 00:10:51,190
上にあることを意味します。

173
00:10:51,190 --> 00:10:54,790
そして4つ目と5つ目の主要な統計量として、

174
00:10:54,790 --> 00:10:59,350
外れ値を含まない最小値と最大値も

175
00:10:59,350 --> 00:11:03,190
プロット上に示されます。

176
00:11:03,190 --> 00:11:07,330
したがって、中心、散らばり、

177
00:11:07,330 --> 00:11:11,500
そして潜在的な外れ値を点として可視化するのにも役立ちます。

