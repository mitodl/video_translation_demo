1
00:00:05,053 --> 00:00:06,220
讲师：大家好。

2
00:00:06,220 --> 00:00:07,520
欢迎回来。

3
00:00:07,520 --> 00:00:09,760
在今天的课程中，我们将要讨论

4
00:00:09,760 --> 00:00:14,120
用于数据探索与分析的统计学。

5
00:00:14,120 --> 00:00:16,880
先从一个简单的问题开始。

6
00:00:16,880 --> 00:00:18,920
什么是统计学？

7
00:00:18,920 --> 00:00:22,680
严格来说，统计学是数学的一个分支，专注于

8
00:00:22,680 --> 00:00:25,540
收集、分析、解释

9
00:00:25,540 --> 00:00:29,920
并展示数据，以提炼洞见并支持

10
00:00:29,920 --> 00:00:31,720
更好的决策。

11
00:00:31,720 --> 00:00:36,360
在本次课程中，我们将聚焦于描述性统计，这些方法

12
00:00:36,360 --> 00:00:39,120
帮助我们汇总和可视化数据，

13
00:00:39,120 --> 00:00:42,480
从而揭示模式与趋势。

14
00:00:42,480 --> 00:00:45,040
我们从一个例子开始。

15
00:00:45,040 --> 00:00:48,400
假设我们想研究

16
00:00:48,400 --> 00:00:51,560
就读于 Universal AI 的学生的身高。

17
00:00:51,560 --> 00:00:56,720
我们不去测量 UAI 每位学生的身高，

18
00:00:56,720 --> 00:00:58,400
而是抽取一个样本——

19
00:00:58,400 --> 00:01:02,650
例如，随机选取100名学生。

20
00:01:02,650 --> 00:01:07,730
这就得到一个包含100个身高值的数据集。

21
00:01:07,730 --> 00:01:11,090
现在我们可以开始对这些数据进行可视化，

22
00:01:11,090 --> 00:01:15,370
例如，将所有抽样学生的身高

23
00:01:15,370 --> 00:01:17,690
并排绘制出来。

24
00:01:17,690 --> 00:01:20,770
当然，我们可以对数值进行排序以识别

25
00:01:20,770 --> 00:01:26,050
趋势，即大多数学生身高相近。

26
00:01:26,050 --> 00:01:29,810
那么，典型学生的身高是多少呢？

27
00:01:29,810 --> 00:01:33,650
有三种常见方式来描述这一点。

28
00:01:33,650 --> 00:01:38,350
我们可以计算算术平均身高，即均值，

29
00:01:38,350 --> 00:01:41,290
为65英寸。

30
00:01:41,290 --> 00:01:43,770
接下来，我们可以找到中位数，它

31
00:01:43,770 --> 00:01:47,890
代表当数据排序后位于中间的值。

32
00:01:47,890 --> 00:01:52,530
也就是说，有50名学生比这个值矮，50名学生

33
00:01:52,530 --> 00:01:55,530
比这个值高。

34
00:01:55,530 --> 00:01:58,890
最后，我们还可以确定众数，它

35
00:01:58,890 --> 00:02:02,410
是出现最频繁的数值。

36
00:02:02,410 --> 00:02:07,070
我们可以把这些身高分到等宽的区间中，然后统计

37
00:02:07,070 --> 00:02:10,389
每个区间中有多少学生。

38
00:02:10,389 --> 00:02:12,750
这种计数与分箱的过程

39
00:02:12,750 --> 00:02:15,870
是用于探索分布的一种可视化技术的基础。

40
00:02:15,870 --> 00:02:18,990
在这里我们可以看到大多数学生肖高集中在什么位置，

41
00:02:18,990 --> 00:02:22,790
以及它们在范围内的分布情况。

42
00:02:22,790 --> 00:02:26,670
少数人相对较高，

43
00:02:26,670 --> 00:02:29,210
但大多数身高聚集在中心附近。

44
00:02:29,210 --> 00:02:33,390
现在，我们可以不用单个点，

45
00:02:33,390 --> 00:02:36,370
而用条形图来制作直方图。

46
00:02:36,370 --> 00:02:41,670
直方图显示每个区间中数值出现的频率，

47
00:02:41,670 --> 00:02:46,390
或者在我们的例子中，即每个身高范围的频次。

48
00:02:46,390 --> 00:02:49,910
这为我们提供了样本分布的清晰图景，

49
00:02:49,910 --> 00:02:54,910
展示大多数学生的位置以及其余人的分散情况。

50
00:02:54,910 --> 00:03:00,190
我们可以改变区间大小——

51
00:03:00,190 --> 00:03:03,230
也就是积分大小——来看

52
00:03:03,230 --> 00:03:06,040
数据中能看到多少变异性。

53
00:03:06,040 --> 00:03:09,120
较小的区间大小可以在更高的粒度上展示变化，

54
00:03:09,120 --> 00:03:11,600
而较大的区间大小会

55
00:03:11,600 --> 00:03:15,880
减少可见细节。

56
00:03:15,880 --> 00:03:18,200
因此，如果区间过小，结果

57
00:03:18,200 --> 00:03:22,120
可能会很嘈杂；而如果区间过大，

58
00:03:22,120 --> 00:03:26,020
分布可能会被过度简化。

59
00:03:26,020 --> 00:03:30,080
我们还可以使用核密度估计（Kernel Density Estimation），

60
00:03:30,080 --> 00:03:34,920
或简称 KDE，来展示数据，它提供一种比

61
00:03:34,920 --> 00:03:39,080
传统直方图更平滑的替代方案。

62
00:03:39,080 --> 00:03:41,760
与直方图不同，KDE 不依赖区间大小，

63
00:03:41,760 --> 00:03:46,920
并能更清晰地可视化

64
00:03:46,920 --> 00:03:50,720
数据分布的形状。

65
00:03:50,720 --> 00:03:53,240
另一个替代方案是小提琴图，它是一个镜像的 KDE。

66
00:03:53,240 --> 00:03:59,440
它适用于比较两个分布，

67
00:03:59,440 --> 00:04:03,120
比如我们示例中男女学生身高的分布。

68
00:04:03,120 --> 00:04:06,260
说到数据形状，偏度是一个有用的度量，

69
00:04:06,260 --> 00:04:09,220
它刻画数据分布的不对称性，或倾斜程度。

70
00:04:09,220 --> 00:04:13,780
它帮助我们理解数据是否偏向

71
00:04:13,780 --> 00:04:19,899
分布的一侧。

72
00:04:19,899 --> 00:04:23,940
例如，如果各点均匀地

73
00:04:23,940 --> 00:04:25,980
分布在中心周围，数据

74
00:04:25,980 --> 00:04:29,020
是对称的，不显示偏度。

75
00:04:29,020 --> 00:04:31,380
如果大多数数据点聚集在左侧，

76
00:04:31,380 --> 00:04:34,300
右侧有一条长尾，我们称之为正偏。

77
00:04:34,300 --> 00:04:37,740
如果大多数点聚集在右侧，

78
00:04:37,740 --> 00:04:43,020
左侧有一条长尾，那就是负偏。

79
00:04:43,020 --> 00:04:45,980
在一个完全对称的分布中，

80
00:04:45,980 --> 00:04:50,260
均值、中位数和众数是相同的。

81
00:04:50,260 --> 00:04:52,980
然而，在不对称或偏态分布中，

82
00:04:52,980 --> 00:04:57,300
这三个度量并不相同。

83
00:04:57,300 --> 00:05:01,300
我们来谈谈异常值。

84
00:05:01,300 --> 00:05:04,500
异常值是数据集中异常高或异常低的数值。

85
00:05:04,500 --> 00:05:07,590
虽然在很多情况下，异常值是预期存在的，

86
00:05:07,590 --> 00:05:13,710
它们也可能由于错误而产生。

87
00:05:13,710 --> 00:05:17,050
例如，假设我们通过让学生报告身高

88
00:05:17,050 --> 00:05:19,670
来进行学生身高的研究，而有一位学生

89
00:05:19,670 --> 00:05:22,830
开玩笑地把自己的身高报成埃菲尔铁塔的高度。

90
00:05:22,830 --> 00:05:26,190
现在，当我们绘制结果时，直方图

91
00:05:26,190 --> 00:05:29,390
可能会变成这样。

92
00:05:29,390 --> 00:05:34,630
我们的均值现在被扭曲了。

93
00:05:34,630 --> 00:05:37,230
它上升到了190英寸以上。

94
00:05:37,230 --> 00:05:39,590
这说明一个异常值就能对均值产生很大影响。

95
00:05:39,590 --> 00:05:41,650
然而，中位数仍然大约为65英寸，

96
00:05:41,650 --> 00:05:45,470
反映了数据真正的集中趋势。

97
00:06:00,630 --> 00:06:05,030
当我们检查这个数据集时，我们会发现这个极高的

98
00:06:05,030 --> 00:06:08,290
数值显然是错误的。

99
00:06:08,290 --> 00:06:12,730
为了有效分析我们的数据，我们可以放心地将其删除。

100
00:06:12,730 --> 00:06:16,330
这就是为什么始终要对数据进行可视化检查，

101
00:06:16,330 --> 00:06:21,250
在进行分析或得出结论之前。

102
00:06:21,250 --> 00:06:24,290
确保一切都有道理。

103
00:06:24,290 --> 00:06:27,850
回到我们的描述性统计，

104
00:06:27,850 --> 00:06:32,370
当数据是对称的时，均值是适合使用的。

105
00:06:32,370 --> 00:06:34,650
中位数特别有用，

106
00:06:34,650 --> 00:06:37,530
当存在离群值时，因为它

107
00:06:37,530 --> 00:06:40,570
对极端值更稳健，

108
00:06:40,570 --> 00:06:42,450
就像我们刚才看到的那个一样。

109
00:06:42,450 --> 00:06:44,610
最后，众数通常用于

110
00:06:44,610 --> 00:06:48,690
类别型数据，它表示最频繁

111
00:06:48,690 --> 00:06:51,450
出现的类别。

112
00:06:51,450 --> 00:06:55,370
接下来我们来谈谈方差和标准差。

113
00:06:55,370 --> 00:06:59,850
方差和标准差是描述连续数据中数值离散程度的

114
00:06:59,850 --> 00:07:03,690
两种最常见方式。

115
00:07:03,690 --> 00:07:05,250
数据集。

116
00:07:05,250 --> 00:07:09,340
样本方差等于各观测值与样本均值之差的平方和，

117
00:07:09,340 --> 00:07:13,620
再除以 n 减 1，

118
00:07:13,620 --> 00:07:15,900
其中 n 是样本量。

119
00:07:15,900 --> 00:07:20,540
标准差是该方差的平方根。

120
00:07:20,540 --> 00:07:24,460
这两者都量化了各个数值

121
00:07:24,460 --> 00:07:27,340
偏离均值的程度。

122
00:07:27,340 --> 00:07:30,300
为什么标准差很重要？

123
00:07:30,300 --> 00:07:34,060
标准差显示数据点在均值周围

124
00:07:34,060 --> 00:07:36,260
的分散程度。

125
00:07:36,260 --> 00:07:40,620
它帮助我们理解数据的一致性。

126
00:07:40,620 --> 00:07:44,340
值越小表示数据越紧密聚集，

127
00:07:44,340 --> 00:07:48,300
而值越大表示离散程度更高、变异性更大。

128
00:07:50,220 --> 00:07:56,300
它表示数据点到均值的平均距离。

129
00:07:56,300 --> 00:07:59,380
在正态分布中，会出现一个特别

130
00:07:59,380 --> 00:08:01,540
有趣的现象。

131
00:08:01,540 --> 00:08:07,380
大约 68% 的数据落在距均值一个标准差

132
00:08:07,380 --> 00:08:09,200
的范围内——

133
00:08:09,200 --> 00:08:13,840
也就是在均值减去 1 个标准差

134
00:08:13,840 --> 00:08:18,240
与均值加上 1 个标准差之间。

135
00:08:18,240 --> 00:08:23,200
此外，如果我们将范围扩展到均值减去两个

136
00:08:23,200 --> 00:08:28,360
标准差和均值加上两个标准差，

137
00:08:28,360 --> 00:08:33,360
我们将包含 95% 的样本。

138
00:08:33,360 --> 00:08:38,200
最后，当我们观察从均值减去三个

139
00:08:38,200 --> 00:08:43,400
标准差到均值加上三个标准差的范围时，

140
00:08:43,400 --> 00:08:45,640
该范围将包含几乎全部

141
00:08:45,640 --> 00:08:51,320
样本，约为 99.7%。

142
00:08:51,320 --> 00:08:59,640
这被称为经验法则，或 68-95-99.7 法则，

143
00:08:59,640 --> 00:09:05,200
并且仅适用于正态分布。

144
00:09:05,200 --> 00:09:09,650
我们还来谈谈分位数和百分位数。

145
00:09:09,650 --> 00:09:13,690
分位数是将数据集划分为

146
00:09:13,690 --> 00:09:17,090
等大小区间的数值。

147
00:09:17,090 --> 00:09:22,930
例如，四分位数将数据分为四个相等部分，

148
00:09:22,930 --> 00:09:27,490
使得每一部分都包含大致相同数量的

149
00:09:27,490 --> 00:09:29,530
数据点。

150
00:09:29,530 --> 00:09:34,130
另一方面，百分位数指的是

151
00:09:34,130 --> 00:09:37,410
数据集中数值的位置。

152
00:09:37,410 --> 00:09:41,210
例如，如果我们有 100 名学生，

153
00:09:41,210 --> 00:09:44,410
并把他们分成四分位组，

154
00:09:44,410 --> 00:09:49,130
每个四分位组将有 25 名学生。

155
00:09:49,130 --> 00:09:54,810
随后我们可以用百分位数来指称这些数据点，

156
00:09:54,810 --> 00:09:57,090
它表示一个数值在数据集中的

157
00:09:57,090 --> 00:10:01,010
排名位置。

158
00:10:01,010 --> 00:10:04,450
箱线图是一种重要的可视化工具，

159
00:10:04,450 --> 00:10:08,990
因为它总结了五个关键统计量。

160
00:10:08,990 --> 00:10:12,510
这里我们可以看到第一四分位数，

161
00:10:12,510 --> 00:10:16,550
它对应于第 25 个百分位，

162
00:10:16,550 --> 00:10:23,790
意味着有 25% 的数据值低于该点。

163
00:10:23,790 --> 00:10:27,230
中位数，即第二四分位数，

164
00:10:27,230 --> 00:10:32,230
或第 50 个百分位，表示一半数据

165
00:10:32,230 --> 00:10:37,470
低于该值，另一半高于该值。

166
00:10:37,470 --> 00:10:42,350
第三四分位数，即第 75 个百分位，

167
00:10:42,350 --> 00:10:48,470
意味着有 75% 的数据低于该值，25%

168
00:10:48,470 --> 00:10:51,190
高于该值。

169
00:10:51,190 --> 00:10:54,790
作为第四和第五个关键统计量，

170
00:10:54,790 --> 00:10:59,350
我们还可以看到最小值和最大值，它们在图中

171
00:10:59,350 --> 00:11:03,190
不包括离群值。

172
00:11:03,190 --> 00:11:07,330
因此，它还帮助我们可视化数据的中心、离散程度，

173
00:11:07,330 --> 00:11:11,500
以及作为点显示的潜在离群值。

