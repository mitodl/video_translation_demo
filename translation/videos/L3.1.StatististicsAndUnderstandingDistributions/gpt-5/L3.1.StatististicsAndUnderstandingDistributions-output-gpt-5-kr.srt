1
00:00:05,053 --> 00:00:06,220
강사: 모두 안녕하세요.

2
00:00:06,220 --> 00:00:07,520
다시 만나서 반갑습니다.

3
00:00:07,520 --> 00:00:09,760
오늘 강의에서는

4
00:00:09,760 --> 00:00:14,120
데이터 탐색과 분석을 위한 통계에 대해 이야기하겠습니다.

5
00:00:14,120 --> 00:00:16,880
간단한 질문부터 시작해 봅시다.

6
00:00:16,880 --> 00:00:18,920
통계란 무엇일까요?

7
00:00:18,920 --> 00:00:22,680
엄밀히 말해, 통계는 수학의 한 분야로서

8
00:00:22,680 --> 00:00:25,540
데이터를 수집, 분석, 해석,

9
00:00:25,540 --> 00:00:29,920
그리고 제시하여 인사이트를 도출하고

10
00:00:29,920 --> 00:00:31,720
더 나은 의사결정을 지원하는 데 초점을 둡니다.

11
00:00:31,720 --> 00:00:36,360
이번 강의에서는 기술통계, 즉

12
00:00:36,360 --> 00:00:39,120
데이터를 요약하고 시각화하여

13
00:00:39,120 --> 00:00:42,480
패턴과 추세를 드러내는 방법에 초점을 맞추겠습니다.

14
00:00:42,480 --> 00:00:45,040
예시로 시작해 봅시다.

15
00:00:45,040 --> 00:00:48,400
Universal AI에 등록된 학생들의 키를

16
00:00:48,400 --> 00:00:51,560
조사하려고 한다고 가정해 봅시다.

17
00:00:51,560 --> 00:00:56,720
UAI의 모든 학생 키를 일일이 측정하는 대신,

18
00:00:56,720 --> 00:00:58,400
표본을 추출합니다--

19
00:00:58,400 --> 00:01:02,650
예를 들어 무작위로 선택한 학생 100명입니다.

20
00:01:02,650 --> 00:01:07,730
이렇게 하면 키 값 100개의 데이터셋이 생깁니다.

21
00:01:07,730 --> 00:01:11,090
이제 이 데이터를 시각화해 볼 수 있는데,

22
00:01:11,090 --> 00:01:15,370
예를 들어, 표본 학생 전원의 키를

23
00:01:15,370 --> 00:01:17,690
나란히 플로팅해 볼 수 있습니다.

24
00:01:17,690 --> 00:01:20,770
물론, 값을 정렬하여

25
00:01:20,770 --> 00:01:26,050
대부분의 학생 키가 비슷하다는 추세를 파악할 수 있습니다.

26
00:01:26,050 --> 00:01:29,810
그렇다면 전형적인 학생의 키는 얼마일까요?

27
00:01:29,810 --> 00:01:33,650
이를 설명하는 흔한 방법은 세 가지가 있습니다.

28
00:01:33,650 --> 00:01:38,350
산술 평균 키, 즉 평균을 계산할 수 있고,

29
00:01:38,350 --> 00:01:41,290
그 값은 65인치입니다.

30
00:01:41,290 --> 00:01:43,770
다음으로 중앙값을 구할 수 있는데,

31
00:01:43,770 --> 00:01:47,890
이는 데이터를 정렬했을 때 가운데 값입니다.

32
00:01:47,890 --> 00:01:52,530
즉, 이 값보다 키가 작은 학생이 50명,

33
00:01:52,530 --> 00:01:55,530
큰 학생이 50명입니다.

34
00:01:55,530 --> 00:01:58,890
마지막으로 최빈값도 확인할 수 있는데,

35
00:01:58,890 --> 00:02:02,410
가장 자주 나타나는 값입니다.

36
00:02:02,410 --> 00:02:07,070
이 키들을 동일한 크기의 구간으로 묶고,

37
00:02:07,070 --> 00:02:10,389
각 구간에 해당하는 학생 수를 셉니다.

38
00:02:10,389 --> 00:02:12,750
이렇게 세고 구간화하는 과정은

39
00:02:12,750 --> 00:02:15,870
분포를 탐색하는 데 쓰이는 시각화 기법의

40
00:02:15,870 --> 00:02:18,990
기초가 됩니다.

41
00:02:18,990 --> 00:02:22,790
여기서 대부분의 학생 키가 어디에 집중되어 있는지,

42
00:02:22,790 --> 00:02:26,670
또 범위 전반에 걸쳐 어떻게 퍼져 있는지를 볼 수 있습니다.

43
00:02:26,670 --> 00:02:29,210
몇몇 개인은 상대적으로 키가 크지만,

44
00:02:29,210 --> 00:02:33,390
대부분의 키는 중심 주변에 모여 있습니다.

45
00:02:33,390 --> 00:02:36,370
이제 개별 점 대신

46
00:02:36,370 --> 00:02:41,670
막대차트를 사용해 히스토그램을 만들 수 있습니다.

47
00:02:41,670 --> 00:02:46,390
히스토그램은 각 구간에서 값이 얼마나 자주 나타나는지,

48
00:02:46,390 --> 00:02:49,910
우리의 경우에는 키 범위에서 얼마나 자주 나타나는지를 보여줍니다.

49
00:02:49,910 --> 00:02:54,910
이를 통해 표본 분포가 어떠한지,

50
00:02:54,910 --> 00:03:00,190
대부분의 학생이 어디에 있고 나머지가 어떻게 퍼져 있는지 명확히 볼 수 있습니다.

51
00:03:00,190 --> 00:03:03,230
구간 크기--

52
00:03:03,230 --> 00:03:06,040
적분 단위 크기--를 바꿔서

53
00:03:06,040 --> 00:03:09,120
데이터에서 얼마나 많은 변동성이 보이는지 확인할 수 있습니다.

54
00:03:09,120 --> 00:03:11,600
구간 크기가 작으면

55
00:03:11,600 --> 00:03:15,880
더 높은 세분성으로 변화를 보여주는 반면, 구간 크기가 크면

56
00:03:15,880 --> 00:03:18,200
가시적 세부사항이 줄어듭니다.

57
00:03:18,200 --> 00:03:22,120
그래서 구간이 너무 작으면 결과가

58
00:03:22,120 --> 00:03:26,020
노이즈가 많아질 수 있고, 너무 크면

59
00:03:26,020 --> 00:03:30,080
분포가 과도하게 단순화될 수 있습니다.

60
00:03:30,080 --> 00:03:34,920
또한 커널 밀도 추정,

61
00:03:34,920 --> 00:03:39,080
즉 KDE를 사용해 데이터를 제시할 수 있는데, 이는 전통적인

62
00:03:39,080 --> 00:03:41,760
히스토그램의 매끄러운 대안입니다.

63
00:03:41,760 --> 00:03:46,920
히스토그램과 달리 KDE는 구간 크기에 의존하지 않으며,

64
00:03:46,920 --> 00:03:50,720
데이터 분포의 형태를

65
00:03:50,720 --> 00:03:53,240
더 명확하게 시각화해 줍니다.

66
00:03:53,240 --> 00:03:59,440
또 다른 대안은 바이올린 플롯으로, 이는 KDE를 좌우 대칭으로 반영한 것입니다.

67
00:03:59,440 --> 00:04:03,120
두 분포를 비교하는 데 유용하며,

68
00:04:03,120 --> 00:04:06,260
우리 예시에서 남학생과 여학생의 키 분포처럼

69
00:04:06,260 --> 00:04:09,220
비교할 수 있습니다.

70
00:04:09,220 --> 00:04:13,780
데이터의 형태와 관련해서, 왜도는

71
00:04:13,780 --> 00:04:19,899
데이터 분포의 비대칭성, 즉 기울어짐을 포착하는 유용한 척도입니다.

72
00:04:19,899 --> 00:04:23,940
데이터가 한쪽으로 치우쳤는지,

73
00:04:23,940 --> 00:04:25,980
분포의 한쪽에 있는지를 이해하는 데 도움이 됩니다.

74
00:04:25,980 --> 00:04:29,020
예를 들어, 점들이 중심을 기준으로 고르게

75
00:04:29,020 --> 00:04:31,380
분포되어 있다면, 데이터는

76
00:04:31,380 --> 00:04:34,300
대칭적이며 왜도가 없습니다.

77
00:04:34,300 --> 00:04:37,740
대부분의 데이터 포인트가 왼쪽에 몰려 있고,

78
00:04:37,740 --> 00:04:43,020
오른쪽으로 긴 꼬리가 있으면 이를 양의 왜도라고 합니다.

79
00:04:43,020 --> 00:04:45,980
대부분의 포인트가 오른쪽에 몰려 있고,

80
00:04:45,980 --> 00:04:50,260
왼쪽으로 긴 꼬리가 있으면 이는 음의 왜도입니다.

81
00:04:50,260 --> 00:04:52,980
완전히 대칭적인 분포에서는

82
00:04:52,980 --> 00:04:57,300
평균, 중앙값, 최빈값이 동일합니다.

83
00:04:57,300 --> 00:05:01,300
하지만 비대칭 또는 왜도 있는 분포에서는

84
00:05:01,300 --> 00:05:04,500
이 세 가지 측도가 서로 다릅니다.

85
00:05:04,500 --> 00:05:07,590
이제 이상치에 대해 이야기해 봅시다.

86
00:05:07,590 --> 00:05:13,710
이상치는 우리 데이터셋에서 유난히 크거나 작은 값입니다.

87
00:05:13,710 --> 00:05:17,050
많은 경우 이상치는 예상 가능하지만,

88
00:05:17,050 --> 00:05:19,670
오류로 인해 발생할 수도 있습니다.

89
00:05:19,670 --> 00:05:22,830
예를 들어, 학생들에게

90
00:05:22,830 --> 00:05:26,190
키를 직접 보고하게 해서 학생들의 키에 대한 연구를 진행하는데,

91
00:05:26,190 --> 00:05:29,390
학생 중 한 명이 장난으로

92
00:05:29,390 --> 00:05:34,630
자신의 키를 에펠탑의 높이라고 보고했다고 합시다.

93
00:05:34,630 --> 00:05:37,230
이제 결과를 플로팅하면, 히스토그램이

94
00:05:37,230 --> 00:05:39,590
이런 식으로 보일 수 있습니다.

95
00:05:39,590 --> 00:05:41,650
우리의 평균은 이제 왜곡되었습니다.

96
00:05:41,650 --> 00:05:45,470
190인치를 넘는 수준으로 올라갑니다.

97
00:05:45,470 --> 00:05:51,550
이는 단 하나의 이상치가 평균에 얼마나 큰 영향을 줄 수 있는지 보여줍니다.

98
00:05:51,550 --> 00:05:56,230
하지만 중앙값은 여전히 약 65인치로 남아 있어,

99
00:05:56,230 --> 00:06:00,630
데이터의 진정한 중심 경향을 반영합니다.

100
00:06:00,630 --> 00:06:05,030
데이터 세트를 살펴보면, 이 극도로 높은

101
00:06:05,030 --> 00:06:08,290
값이 명백히 오류라는 것을 알 수 있습니다.

102
00:06:08,290 --> 00:06:12,730
데이터를 효과적으로 분석하기 위해 이것을 안전하게 제거할 수 있습니다.

103
00:06:12,730 --> 00:06:16,330
이것이 왜 항상 시각적으로 점검하는 것이 중요한지,

104
00:06:16,330 --> 00:06:21,250
분석을 수행하거나 결론을 내리기 전에 데이터를

105
00:06:21,250 --> 00:06:24,290
모든 것이 말이 되는지 반드시 확인하세요.

106
00:06:24,290 --> 00:06:27,850
그럼 기술통계로 돌아가서,

107
00:06:27,850 --> 00:06:32,370
평균은 데이터가 대칭일 때 사용하는 것이 적절합니다.

108
00:06:32,370 --> 00:06:34,650
중앙값은 특히 유용한데,

109
00:06:34,650 --> 00:06:37,530
이상치가 존재할 때,

110
00:06:37,530 --> 00:06:40,570
극단값에 더 강건하기

111
00:06:40,570 --> 00:06:42,450
때문입니다. 방금 본 것처럼요.

112
00:06:42,450 --> 00:06:44,610
마지막으로 최빈값은 보통

113
00:06:44,610 --> 00:06:48,690
범주형 데이터에서 사용되며, 가장 자주

114
00:06:48,690 --> 00:06:51,450
나타나는 범주를 나타냅니다.

115
00:06:51,450 --> 00:06:55,370
그럼 분산과 표준편차에 대해 이야기해 봅시다.

116
00:06:55,370 --> 00:06:59,850
분산과 표준편차는 연속형 데이터에서 값들이

117
00:06:59,850 --> 00:07:03,690
얼마나 퍼져 있는지를 설명하는

118
00:07:03,690 --> 00:07:05,250
두 가지 가장 일반적인 방법입니다.

119
00:07:05,250 --> 00:07:09,340
표본분산은 표본평균으로부터의 편차 제곱의 합을

120
00:07:09,340 --> 00:07:13,620
n 마이너스 1로 나눈 값이며,

121
00:07:13,620 --> 00:07:15,900
여기서 n은 표본크기입니다.

122
00:07:15,900 --> 00:07:20,540
표준편차는 이 분산의 제곱근입니다.

123
00:07:20,540 --> 00:07:24,460
이 둘은 모두 개별 값들이

124
00:07:24,460 --> 00:07:27,340
평균에서 얼마나 벗어나는지를 정량화합니다.

125
00:07:27,340 --> 00:07:30,300
표준편차는 왜 중요할까요?

126
00:07:30,300 --> 00:07:34,060
표준편차는 데이터 점들이 평균을 중심으로

127
00:07:34,060 --> 00:07:36,260
얼마나 퍼져 있는지를 보여줍니다.

128
00:07:36,260 --> 00:07:40,620
이는 데이터의 일관성을 이해하는 데 도움이 됩니다.

129
00:07:40,620 --> 00:07:44,340
값이 작을수록 데이터가 촘촘히 모여 있고,

130
00:07:44,340 --> 00:07:48,300
값이 클수록 더 큰 분산과 더 많은

131
00:07:48,300 --> 00:07:50,220
변동을 의미합니다.

132
00:07:50,220 --> 00:07:56,300
평균으로부터 데이터 점의 평균적인 거리를 보여줍니다.

133
00:07:56,300 --> 00:07:59,380
정규분포에서는, 특히

134
00:07:59,380 --> 00:08:01,540
흥미로운 일이 일어납니다.

135
00:08:01,540 --> 00:08:07,380
약 68%의 데이터가 평균에서 한 표준편차

136
00:08:07,380 --> 00:08:09,200
이내에 위치합니다—

137
00:08:09,200 --> 00:08:13,840
즉, 평균 마이너스 1 표준편차와

138
00:08:13,840 --> 00:08:18,240
평균 플러스 1 표준편차 사이입니다.

139
00:08:18,240 --> 00:08:23,200
더 나아가, 이를 평균 마이너스 두

140
00:08:23,200 --> 00:08:28,360
표준편차와 평균 플러스 두 표준편차까지 확장하면,

141
00:08:28,360 --> 00:08:33,360
표본의 95%를 포함하게 됩니다.

142
00:08:33,360 --> 00:08:38,200
마지막으로, 평균 마이너스 세

143
00:08:38,200 --> 00:08:43,400
표준편차에서 평균 플러스 세 표준편차까지의 범위를 보면,

144
00:08:43,400 --> 00:08:45,640
그 범위는 거의 모든

145
00:08:45,640 --> 00:08:51,320
표본을 포함하며, 대략 99.7%입니다.

146
00:08:51,320 --> 00:08:59,640
이는 경험법칙, 또는 68-95-99.7 규칙으로 알려져 있으며,

147
00:08:59,640 --> 00:09:05,200
정규분포에만 적용됩니다.

148
00:09:05,200 --> 00:09:09,650
분위수와 백분위수에 대해서도 이야기해 봅시다.

149
00:09:09,650 --> 00:09:13,690
분위수는 데이터 세트를

150
00:09:13,690 --> 00:09:17,090
동일한 크기의 구간으로 나누는 값입니다.

151
00:09:17,090 --> 00:09:22,930
예를 들어, 사분위수는 데이터를 네 개의 동일한 부분으로 나누어

152
00:09:22,930 --> 00:09:27,490
각 부분에 대략 동일한 수의

153
00:09:27,490 --> 00:09:29,530
데이터 점이 들어가도록 합니다.

154
00:09:29,530 --> 00:09:34,130
한편, 백분위수는 데이터 세트 내에서

155
00:09:34,130 --> 00:09:37,410
값의 위치를 나타냅니다.

156
00:09:37,410 --> 00:09:41,210
예를 들어, 학생이 100명 있고,

157
00:09:41,210 --> 00:09:44,410
그들을 사분위수로 나누면,

158
00:09:44,410 --> 00:09:49,130
각 사분위수에는 25명의 학생이 있게 됩니다.

159
00:09:49,130 --> 00:09:54,810
그런 다음 이러한 데이터 점들을 백분위수를 사용해 언급할 수 있는데,

160
00:09:54,810 --> 00:09:57,090
이는 데이터 세트 내에서 한 값이 차지하는 순위상의 위치를

161
00:09:57,090 --> 00:10:01,010
나타냅니다.

162
00:10:01,010 --> 00:10:04,450
박스플롯은 다섯 가지 핵심 통계를 요약하기 때문에

163
00:10:04,450 --> 00:10:08,990
중요한 시각화 도구입니다.

164
00:10:08,990 --> 00:10:12,510
여기서 제1사분위수를 볼 수 있는데,

165
00:10:12,510 --> 00:10:16,550
이는 25번째 백분위수에 해당하며,

166
00:10:16,550 --> 00:10:23,790
데이터 값의 25%가 이 지점 아래에 위치함을 의미합니다.

167
00:10:23,790 --> 00:10:27,230
중앙값은 제2사분위수,

168
00:10:27,230 --> 00:10:32,230
즉 50번째 백분위수로, 데이터의 절반이

169
00:10:32,230 --> 00:10:37,470
그 값보다 작고 절반은 그보다 큼을 나타냅니다.

170
00:10:37,470 --> 00:10:42,350
제3사분위수, 즉 75번째 백분위수는,

171
00:10:42,350 --> 00:10:48,470
데이터의 75%가 이 값보다 작고 25%가

172
00:10:48,470 --> 00:10:51,190
그보다 큼을 의미합니다.

173
00:10:51,190 --> 00:10:54,790
그리고 네 번째와 다섯 번째 핵심 통계로,

174
00:10:54,790 --> 00:10:59,350
그래프에서 이상치를 포함하지 않는 최솟값과 최댓값도

175
00:10:59,350 --> 00:11:03,190
볼 수 있습니다.

176
00:11:03,190 --> 00:11:07,330
따라서 이는 우리 데이터에서 중심, 분산 정도,

177
00:11:07,330 --> 00:11:11,500
그리고 잠재적 이상치를 점으로 시각화하는 데도 도움이 됩니다.

