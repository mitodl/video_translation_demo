1
00:00:00,000 --> 00:00:04,340
講師：ここまで私たちは単一の変数を分析してきました。

2
00:00:04,340 --> 00:00:06,320
学生の身長です。

3
00:00:06,320 --> 00:00:11,480
この種の分析は一変量解析と呼ばれ、

4
00:00:11,480 --> 00:00:15,920
記述統計を用いて変数の特性を記述・要約することを

5
00:00:15,920 --> 00:00:20,210
目的としています。

6
00:00:20,210 --> 00:00:24,210
平均、中央値、標準偏差のようなものや、

7
00:00:24,210 --> 00:00:30,530
ヒストグラムや箱ひげ図といった可視化・プロットです。

8
00:00:30,530 --> 00:00:35,030
二変量解析では、2つの変数と

9
00:00:35,030 --> 00:00:37,280
その関係を探ります。

10
00:00:37,280 --> 00:00:42,710
そして多変量解析では、3つ以上の変数を

11
00:00:42,710 --> 00:00:46,400
同時に見て、再び

12
00:00:46,400 --> 00:00:51,530
今回はより複雑である可能性のある関係性を理解しようとします。

13
00:00:51,530 --> 00:00:55,160
では、一変量解析である

14
00:00:55,160 --> 00:00:58,880
学生の身長から、二変量解析へ移りましょう。これは

15
00:00:58,880 --> 00:01:03,800
身長データに加えて、学生の体重も含みます。

16
00:01:03,800 --> 00:01:07,270
これで観測変数が2つになりました。

17
00:01:07,270 --> 00:01:09,420
そして両者の関係を定量化することは

18
00:01:09,420 --> 00:01:11,290
興味深いことです――

19
00:01:11,290 --> 00:01:15,810
すなわち、変数がどのように共分散するかを測ることです。

20
00:01:15,810 --> 00:01:19,020
体重と身長は互いに関係しています。

21
00:01:19,020 --> 00:01:23,700
背の高い学生は、背の低い学生よりも体重が重い傾向があります。

22
00:01:23,700 --> 00:01:27,480
それをプロットできます。1つの変数をx軸に、

23
00:01:27,480 --> 00:01:30,210
もう一方をy軸に取ります。

24
00:01:30,210 --> 00:01:33,540
この種のプロットは散布図と呼ばれます。

25
00:01:33,540 --> 00:01:37,980
各点は1人の学生を表します。

26
00:01:37,980 --> 00:01:40,050
散布図の素晴らしいところは、

27
00:01:40,050 --> 00:01:42,970
パターンを見やすくしてくれる点です。

28
00:01:42,970 --> 00:01:46,830
2つの変数が互いにどう関係しているかです。

29
00:01:46,830 --> 00:01:50,310
図では、左から右へ

30
00:01:50,310 --> 00:01:52,230
増加していくパターンが観察できます。

31
00:01:52,230 --> 00:01:55,560
これは体重と身長が

32
00:01:55,560 --> 00:01:58,560
正の相関を持っていることを意味します。

33
00:01:58,560 --> 00:02:00,780
この種の関係は、

34
00:02:00,780 --> 00:02:05,940
二変量解析ではアソシエーション（関連）とも呼ばれます。

35
00:02:05,940 --> 00:02:09,840
線形のアソシエーションとは、点が多かれ少なかれ

36
00:02:09,840 --> 00:02:11,230
一直線状に並ぶことを意味します。

37
00:02:11,230 --> 00:02:15,210
しかし、非線形のアソシエーションも観察されることがあり、

38
00:02:15,210 --> 00:02:18,030
二次関数的なパターンなどがあります。

39
00:02:18,030 --> 00:02:21,150
そして時には、はっきりしたパターンがないこともあり、

40
00:02:21,150 --> 00:02:24,150
図で見られるとおりです。

41
00:02:24,150 --> 00:02:27,820
アソシエーションの形状に加えて、

42
00:02:27,820 --> 00:02:31,170
方向も重要です。

43
00:02:31,170 --> 00:02:34,540
直線の傾きが上向きであれば、

44
00:02:34,540 --> 00:02:37,530
アソシエーションは正です。

45
00:02:37,530 --> 00:02:42,360
傾きが下向きであれば、アソシエーションは負です。

46
00:02:42,360 --> 00:02:46,350
アソシエーションの強さも重要です。

47
00:02:46,350 --> 00:02:49,860
点が直線のまわりに密に集まっていれば、

48
00:02:49,860 --> 00:02:52,890
強いアソシエーションです。

49
00:02:52,890 --> 00:02:57,690
点がより広がっていれば、アソシエーションは弱いです。

50
00:02:57,690 --> 00:03:00,810
強さは

51
00:03:00,810 --> 00:03:03,240
方向に依存しないことに注意が必要です。

52
00:03:03,240 --> 00:03:05,850
強い正のアソシエーションもあれば、

53
00:03:05,850 --> 00:03:09,600
強い負のアソシエーションもあり得ます。

54
00:03:09,600 --> 00:03:13,710
線形のアソシエーションの強さと方向の両方は、

55
00:03:13,710 --> 00:03:18,290
相関係数を使って定量化することもできます。

56
00:03:18,290 --> 00:03:22,270
相関係数はマイナス1から1の範囲をとります。

57
00:03:22,270 --> 00:03:26,090
値が1またはマイナス1に近いほど、

58
00:03:26,090 --> 00:03:29,470
線形関係は強くなります。

59
00:03:29,470 --> 00:03:35,920
0付近の値は、線形のアソシエーションがほとんどないか、ないことを意味します。

60
00:03:35,920 --> 00:03:43,450
例えば、強い正の相関は0.9前後かもしれません。

61
00:03:43,450 --> 00:03:46,720
変数同士が無関係であれば、

62
00:03:46,720 --> 00:03:51,070
0.01のような値が見られるかもしれません。

63
00:03:51,070 --> 00:03:54,910
しかし、相関は

64
00:03:54,910 --> 00:03:56,950
因果関係を意味しないことを念頭に置くべきです。

65
00:03:56,950 --> 00:03:59,440
2つのものが一緒に動くからといって、

66
00:03:59,440 --> 00:04:03,100
一方が他方を引き起こしているとは限りません。

67
00:04:03,100 --> 00:04:07,640
身長と体重が関係しているという私たちの例でさえ、

68
00:04:07,640 --> 00:04:10,960
その関係は直接的な因果ではありません。

69
00:04:10,960 --> 00:04:14,380
たしかに相関はありますが、身長が直接

70
00:04:14,380 --> 00:04:15,380
体重の原因となっているわけではありません。

71
00:04:15,380 --> 00:04:20,089
代わりに、年齢、栄養、

72
00:04:20,089 --> 00:04:24,110
生物学といった共通の基礎要因が両者に影響します。

73
00:04:24,110 --> 00:04:27,350
また、共分散を使って、

74
00:04:27,350 --> 00:04:29,780
2つの変数が一緒にどう変動するかを測ることもできます。

75
00:04:29,780 --> 00:04:32,000
共分散は、2つが一緒に増減するなら

76
00:04:32,000 --> 00:04:34,730
正になります。

77
00:04:34,730 --> 00:04:38,840
一方が増え、他方が減るなら負になります。

78
00:04:38,840 --> 00:04:44,900
一貫したパターンがなければ、共分散は0に近くなります。

79
00:04:44,900 --> 00:04:49,310
共分散と相関はいずれも要約統計量で、

80
00:04:49,310 --> 00:04:52,310
2つの観測値の集合が

81
00:04:52,310 --> 00:04:54,170
互いにどう関係しているかを記述します。

82
00:04:54,170 --> 00:04:57,120
共分散は関係の方向を示しますが、

83
00:04:57,120 --> 00:05:00,140
強さを意味のある形では示しません。

84
00:05:00,140 --> 00:05:03,590
一方、相関は

85
00:05:03,590 --> 00:05:08,450
線形関係の方向と強さの両方を定量化するのに役立ちます。

86
00:05:08,450 --> 00:05:13,580
では、古典的な統計現象である

87
00:05:13,580 --> 00:05:16,220
シンプソンのパラドックスについて話しましょう。

88
00:05:16,220 --> 00:05:19,430
学生の身長と、

89
00:05:19,430 --> 00:05:24,630
バスケットボールで彼らが何点取るかのデータを集めるとします。

90
00:05:24,630 --> 00:05:27,280
全体のデータを見ると、

91
00:05:27,280 --> 00:05:31,590
この2つの変数は負に

92
00:05:31,590 --> 00:05:32,740
相関しているように見えるかもしれません。

93
00:05:32,740 --> 00:05:38,918
つまり、背の高い学生ほど点を取らないように見えるのです。

94
00:05:38,918 --> 00:05:40,830
ふむ。

95
00:05:40,830 --> 00:05:43,410
しかし、データを

96
00:05:43,410 --> 00:05:47,140
男性と女性の2つのサブグループに分けると、

97
00:05:47,140 --> 00:05:50,140
各グループ内では、

98
00:05:50,140 --> 00:05:54,060
背の高い学生ほど点を取る傾向があることがわかるかもしれません。

99
00:05:54,060 --> 00:05:57,880
つまり全体のデータは負の相関を示唆していますが、

100
00:05:57,880 --> 00:06:01,800
サブグループのデータは正の相関を示しているのです。

101
00:06:01,800 --> 00:06:04,530
両方のグループで。

102
00:06:04,530 --> 00:06:06,900
それはどういう意味ですか？

103
00:06:06,900 --> 00:06:10,680
つまり、別の要因、別の変数があるということです――

104
00:06:10,680 --> 00:06:12,580
この場合は、性別――

105
00:06:12,580 --> 00:06:15,690
が、観測された関係に影響を与えているのです。

106
00:06:15,690 --> 00:06:20,250
この変数は交絡変数と呼ばれます。

107
00:06:20,250 --> 00:06:22,770
用語の観点では、私たちは

108
00:06:22,770 --> 00:06:27,420
身長を独立変数、バスケットボールの得点を

109
00:06:27,420 --> 00:06:30,390
従属変数と呼びます。

110
00:06:30,390 --> 00:06:33,270
つまり、シンプソンのパラドックスの本質は、

111
00:06:33,270 --> 00:06:37,780
この場合の性別のようなサブグループを無視すると、

112
00:06:37,780 --> 00:06:40,900
全体的な傾向が誤解を招く可能性があるということです。

113
00:06:40,900 --> 00:06:43,530
言い換えれば、異なるデータ群では現れている傾向が

114
00:06:43,530 --> 00:06:48,570
群を結合すると消えたり逆転したりする

115
00:06:48,570 --> 00:06:51,840
ということです。

116
00:06:51,840 --> 00:06:54,030
それは、潜在変数や交絡変数によって生じる

117
00:06:54,030 --> 00:06:57,870
統計的な錯覚であり、それらが

118
00:06:57,870 --> 00:07:00,540
観測された関係に影響を及ぼしているのです。

119
00:07:00,540 --> 00:07:03,270
このパラドックスはもう一つの重要な警鐘であり、

120
00:07:03,270 --> 00:07:07,200
相関は因果を意味しないということを思い起こさせます。

121
00:07:07,200 --> 00:07:10,470
では、典型的な例と対比してみましょう――

122
00:07:10,470 --> 00:07:12,430
見せかけの相関です。

123
00:07:12,430 --> 00:07:15,600
アイスクリームの売上とサメの襲撃。

124
00:07:15,600 --> 00:07:18,340
この二つの変数には相関があります。

125
00:07:18,340 --> 00:07:22,780
しかし、アイスクリームを食べるとサメの襲撃が起きるのでしょうか？

126
00:07:22,780 --> 00:07:24,480
もちろん違います。

127
00:07:24,480 --> 00:07:27,360
本当の説明は第3の要因です。

128
00:07:27,360 --> 00:07:31,320
暑い天候はアイスクリームの売上とビーチでの

129
00:07:31,320 --> 00:07:36,070
活動の両方を増やし、その結果としてサメの襲撃の可能性が高まります。

130
00:07:36,070 --> 00:07:40,180
これが、私たちが見せかけの、あるいは誤解を招く相関と呼ぶものです。つまり、

131
00:07:40,180 --> 00:07:44,560
二つの変数が関連しているように見えても、そのつながりは実際には

132
00:07:44,560 --> 00:07:47,890
外部要因によって駆動されているのです。

133
00:07:47,890 --> 00:07:51,340
本日の講義のまとめとして、

134
00:07:51,340 --> 00:07:53,980
データを可視化する方法について、

135
00:07:53,980 --> 00:07:57,470
ヒストグラム、箱ひげ図、散布図を用いて話し、

136
00:07:57,470 --> 00:08:02,050
代表値、散らばり、

137
00:08:02,050 --> 00:08:05,950
および変数間の関係といった重要な考え方を探りました。

138
00:08:05,950 --> 00:08:10,840
ここまで、変数がどのように関連し得るか――

139
00:08:10,840 --> 00:08:14,740
方向だけでなく、その形や強さについても――を見てきました。

140
00:08:14,740 --> 00:08:16,540
です。

141
00:08:16,540 --> 00:08:20,380
そして、そうしたパターンを定量化する道具として

142
00:08:20,380 --> 00:08:24,370
相関と共分散に移りました。

143
00:08:24,370 --> 00:08:28,340
結局のところ、統計は単に数字を計算することではありません。

144
00:08:28,340 --> 00:08:31,360
不確実性の下で意思決定を行うことであり、

145
00:08:31,360 --> 00:08:36,159
それを慎重に、明確に、透明性をもって行うことです。

146
00:08:36,159 --> 00:08:38,640
次の講義でお会いしましょう。

