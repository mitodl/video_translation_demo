1
00:00:00,000 --> 00:00:04,340
강사: 지금까지 우리는 단일 변수를 분석했습니다.

2
00:00:04,340 --> 00:00:06,320
학생들의 키입니다.

3
00:00:06,320 --> 00:00:11,480
이 유형의 분석을 단변량 분석이라고 하며,

4
00:00:11,480 --> 00:00:15,920
목표는 기술 통계를 사용하여 변수의

5
00:00:15,920 --> 00:00:20,210
특성을 설명하고 요약하는 것입니다.

6
00:00:20,210 --> 00:00:24,210
평균, 중앙값, 표준 편차와 같은 것들,

7
00:00:24,210 --> 00:00:30,530
그리고 히스토그램 및 박스 플롯과 같은 시각화, 도표입니다.

8
00:00:30,530 --> 00:00:35,030
이변량 분석에서는 두 변수를 탐구하고

9
00:00:35,030 --> 00:00:37,280
그들의 관계를 살펴봅니다.

10
00:00:37,280 --> 00:00:42,710
그리고 다변량 분석에서는 세 개 이상의 변수를

11
00:00:42,710 --> 00:00:46,400
동시에 살펴보고, 다시 한번 그들의,

12
00:00:46,400 --> 00:00:51,530
이번에는 더 복잡할 수 있는 관계를 이해하려고 합니다.

13
00:00:51,530 --> 00:00:55,160
그럼 학생들의 키에 대한 단변량 분석에서

14
00:00:55,160 --> 00:00:58,880
이변량 분석으로 넘어갑시다. 이 분석은

15
00:00:58,880 --> 00:01:03,800
키 데이터 외에도 학생들의 체중을 포함합니다.

16
00:01:03,800 --> 00:01:07,270
이제 우리는 두 개의 관측 변수를 가지고 있습니다.

17
00:01:07,270 --> 00:01:09,420
그리고 이들 사이의 관계를 정량화하는 것이 흥미롭습니다.

18
00:01:09,420 --> 00:01:11,290
즉, 변수들이 어떻게 공변하는지를 측정하는 것입니다.

19
00:01:11,290 --> 00:01:15,810
체중과 키는 서로 관련이 있습니다.

20
00:01:15,810 --> 00:01:19,020
더 큰 키를 가진 학생들이 더 작은 키를 가진 학생들보다

21
00:01:19,020 --> 00:01:23,700
체중이 더 나가는 경향이 있습니다.

22
00:01:23,700 --> 00:01:27,480
이를 그래프로 나타낼 수 있습니다. 한 변수는 x축에,

23
00:01:27,480 --> 00:01:30,210
다른 변수는 y축에 표시합니다.

24
00:01:30,210 --> 00:01:33,540
이러한 유형의 그래프를 산포도라고 합니다.

25
00:01:33,540 --> 00:01:37,980
각 점은 한 명의 학생을 나타냅니다.

26
00:01:37,980 --> 00:01:40,050
산포도의 큰 장점은

27
00:01:40,050 --> 00:01:42,970
우리가 패턴을 볼 수 있게 도와준다는 것입니다.

28
00:01:42,970 --> 00:01:46,830
서로 다른 두 변수가 어떻게 관계되는지를 말이죠.

29
00:01:46,830 --> 00:01:50,310
그림에서 우리는 왼쪽에서 오른쪽으로 증가하는 패턴을

30
00:01:50,310 --> 00:01:52,230
관찰할 수 있습니다.

31
00:01:52,230 --> 00:01:55,560
이는 체중과 키가 긍정적으로

32
00:01:55,560 --> 00:01:58,560
상관되어 있음을 의미합니다.

33
00:01:58,560 --> 00:02:00,780
이러한 유형의 관계는 이변량 분석에서

34
00:02:00,780 --> 00:02:05,940
연관성이라고도 불립니다.

35
00:02:05,940 --> 00:02:09,840
선형 연관성은 점들이 대략

36
00:02:09,840 --> 00:02:11,230
직선을 형성한다는 것을 의미합니다.

37
00:02:11,230 --> 00:02:15,210
그러나 비선형 연관성도 관찰할 수 있으며,

38
00:02:15,210 --> 00:02:18,030
예를 들어, 이차 패턴이 있을 수 있습니다.

39
00:02:18,030 --> 00:02:21,150
때때로 명확한 패턴이 없는 경우도 있으며,

40
00:02:21,150 --> 00:02:24,150
그림에서 볼 수 있습니다.

41
00:02:24,150 --> 00:02:27,820
연관성의 형태 외에도,

42
00:02:27,820 --> 00:02:31,170
방향도 중요합니다.

43
00:02:31,170 --> 00:02:34,540
선의 기울기가 상승하면,

44
00:02:34,540 --> 00:02:37,530
연관성이 긍정적임을 의미합니다.

45
00:02:37,530 --> 00:02:42,360
기울기가 하락하면 연관성이 부정적입니다.

46
00:02:42,360 --> 00:02:46,350
연관성의 강도도 중요합니다.

47
00:02:46,350 --> 00:02:49,860
점들이 선 주위에 밀집되어 있다면,

48
00:02:49,860 --> 00:02:52,890
강한 연관성입니다.

49
00:02:52,890 --> 00:02:57,690
점들이 더 분산되어 있다면 연관성은 약합니다.

50
00:02:57,690 --> 00:03:00,810
강도가 방향에 의존하지 않는다는 점은

51
00:03:00,810 --> 00:03:03,240
중요합니다.

52
00:03:03,240 --> 00:03:05,850
강한 긍정적 연관성이나

53
00:03:05,850 --> 00:03:09,600
강한 부정적 연관성을 가질 수 있습니다.

54
00:03:09,600 --> 00:03:13,710
선형 연관성의 강도와 방향도 정량화할 수 있으며,

55
00:03:13,710 --> 00:03:18,290
상관 계수를 사용합니다.

56
00:03:18,290 --> 00:03:22,270
상관 계수는 마이너스 1에서 1까지의 범위를 가집니다.

57
00:03:22,270 --> 00:03:26,090
값이 1이나 마이너스 1에 가까울수록,

58
00:03:26,090 --> 00:03:29,470
선형 관계가 강해집니다.

59
00:03:29,470 --> 00:03:35,920
0에 가까운 값은 선형 연관성이 거의 없음을 의미합니다.

60
00:03:35,920 --> 00:03:43,450
예를 들어, 강한 긍정적 상관관계는 0.9 정도일 수 있습니다.

61
00:03:43,450 --> 00:03:46,720
변수들이 관련이 없으면, 우리는

62
00:03:46,720 --> 00:03:51,070
0.01과 같은 값을 볼 수 있습니다.

63
00:03:51,070 --> 00:03:54,910
하지만 상관관계가

64
00:03:54,910 --> 00:03:56,950
인과관계를 의미하지 않는다는 점은 염두에 두어야 합니다.

65
00:03:56,950 --> 00:03:59,440
두 가지가 함께 움직인다고 해서

66
00:03:59,440 --> 00:04:03,100
하나가 다른 것을 유발한다는 의미는 아닙니다.

67
00:04:03,100 --> 00:04:07,640
직접적 인과 관계는 없지만,

68
00:04:07,640 --> 00:04:10,960
키와 체중은 관련이 있습니다.

69
00:04:10,960 --> 00:04:14,380
네, 이 둘은 상관관계가 있지만,

70
00:04:14,380 --> 00:04:15,380
키가 체중을 직접적으로

71
00:04:15,380 --> 00:04:20,089
유발하는 것은 아닙니다.

72
00:04:20,089 --> 00:04:24,110
대신 연령, 영양 등과 같은 공통의 기저 요인이

73
00:04:24,110 --> 00:04:27,350
둘 다에 영향을 미칩니다.

74
00:04:27,350 --> 00:04:29,780
우리는 또한 공분산을 사용하여

75
00:04:29,780 --> 00:04:32,000
두 변수가 함께 어떻게 변동하는지를 측정할 수 있습니다.

76
00:04:32,000 --> 00:04:34,730
공분산이 양수라면 두 변수가

77
00:04:34,730 --> 00:04:38,840
함께 증가하거나 감소합니다.

78
00:04:38,840 --> 00:04:44,900
한 변수가 증가하는 동안 다른 변수가 감소하면

79
00:04:44,900 --> 00:04:49,310
공분산은 음수입니다.

80
00:04:49,310 --> 00:04:52,310
일관된 패턴이 없으면 공분산은 0에 가깝습니다.

81
00:04:52,310 --> 00:04:54,170
공분산과 상관관계는 두 집합의 관측값이

82
00:04:54,170 --> 00:04:57,120
서로 어떻게 관련되는지를 설명하는 요약 통계입니다.

83
00:04:57,120 --> 00:05:00,140
공분산은 관계의 방향을 알려주지만,

84
00:05:00,140 --> 00:05:03,590
의미 있는 방식으로 강도를 나타내지는 않습니다.

85
00:05:03,590 --> 00:05:08,450
반면에 상관관계는 선형 관계의

86
00:05:08,450 --> 00:05:13,580
방향과 강도를 정량화하는 데 도움을 줍니다.

87
00:05:13,580 --> 00:05:16,220
이제 고전적인 통계적 현상에 대해 이야기하겠습니다.

88
00:05:16,220 --> 00:05:19,430
심슨의 역설입니다.

89
00:05:19,430 --> 00:05:24,630
학생들의 키와 농구 점수를 수집한다고 가정해봅시다.

90
00:05:24,630 --> 00:05:27,280
전체 데이터를 살펴보면,

91
00:05:27,280 --> 00:05:31,590
이 두 변수는 부정적으로

92
00:05:31,590 --> 00:05:32,740
상관되어 있는 것처럼 보일 수 있습니다.

93
00:05:32,740 --> 00:05:38,918
즉, 키가 큰 학생들이 점수를 덜 얻는 것처럼 보입니다.

94
00:05:38,918 --> 00:05:40,830
흠.

95
00:05:40,830 --> 00:05:43,410
하지만 데이터를 두 개의 하위 그룹으로 나누면,

96
00:05:43,410 --> 00:05:47,140
남성과 여성으로,

97
00:05:47,140 --> 00:05:50,140
각 그룹 내에서 더 큰 키를 가진 학생들이

98
00:05:50,140 --> 00:05:54,060
더 많은 점수를 얻는 경향이 있음을 발견할 수 있습니다.

99
00:05:54,060 --> 00:05:57,880
그래서 전체 데이터는 부정적 상관관계를 제시하지만,

100
00:05:57,880 --> 00:06:01,800
하위 그룹 데이터는 긍정적 상관관계를 드러냅니다.

101
00:06:01,800 --> 00:06:04,530
두 그룹 모두.

102
00:06:04,530 --> 00:06:06,900
그게 무슨 뜻인가요?

103
00:06:06,900 --> 00:06:10,680
다른 요인, 다른 변수--

104
00:06:10,680 --> 00:06:12,580
이 경우, 성별--

105
00:06:12,580 --> 00:06:15,690
이 관찰된 관계에 영향을 미친다는 뜻입니다.

106
00:06:15,690 --> 00:06:20,250
이 변수를 혼란 변수라고 합니다.

107
00:06:20,250 --> 00:06:22,770
용어적으로 우리는

108
00:06:22,770 --> 00:06:27,420
신장을 독립 변수라고 하고 농구 점수를

109
00:06:27,420 --> 00:06:30,390
종속 변수라고 부릅니다.

110
00:06:30,390 --> 00:06:33,270
그래서 심슨의 역설의 본질은

111
00:06:33,270 --> 00:06:37,780
이 경우 성별과 같은 하위 그룹을 무시하면,

112
00:06:37,780 --> 00:06:40,900
전체 경향이 오해의 소지가 있을 수 있다는 것입니다.

113
00:06:40,900 --> 00:06:43,530
다시 말해, 데이터의 서로 다른 그룹에서 나타나는 경향이

114
00:06:43,530 --> 00:06:48,570
그룹이 결합될 때 사라지거나 반전됩니다.

115
00:06:48,570 --> 00:06:51,840
이것은 관찰된 관계에 영향을 미치는

116
00:06:51,840 --> 00:06:54,030
이런 잠재적이거나 혼란 변수들로 인해 발생하는 통계적 환상입니다.

117
00:06:54,030 --> 00:06:57,870
이 역설은 상관관계가 인과관계를 의미하지 않는다는

118
00:06:57,870 --> 00:07:00,540
중요한 또 다른 경고입니다.

119
00:07:00,540 --> 00:07:03,270
이제, 이를 가짜 상관관계의 고전적인 예와 대조해보세요.

120
00:07:03,270 --> 00:07:07,200
아이스크림 판매와 상어 공격입니다.

121
00:07:07,200 --> 00:07:10,470
이 두 변수는 상관관계가 있습니다.

122
00:07:10,470 --> 00:07:12,430
하지만 아이스크림을 먹는 것이 상어 공격을 일으키나요?

123
00:07:12,430 --> 00:07:15,600
물론 그렇지 않습니다.

124
00:07:15,600 --> 00:07:18,340
진짜 설명은 제3의 요인입니다.

125
00:07:18,340 --> 00:07:22,780
더운 날씨는 아이스크림 판매와 해변 활동을 모두 증가시켜,

126
00:07:22,780 --> 00:07:24,480
그 결과 상어 공격의 가능성을 높입니다.

127
00:07:24,480 --> 00:07:27,360
이것이 우리가 가짜 또는 오해의 소지가 있는 상관관계라고 부르는 것입니다. 두 변수는 관련이 있는 것처럼 보이지만

128
00:07:27,360 --> 00:07:31,320
연결은 실제로 외부 요인에 의해 좌우됩니다.

129
00:07:31,320 --> 00:07:36,070
오늘 강의에서 요약하자면,

130
00:07:36,070 --> 00:07:40,180
우리는 데이터 시각화를 어떻게 하는지에 대해 논의했습니다.

131
00:07:40,180 --> 00:07:44,560
히스토그램, 박스 플롯, 분산도를 사용하여,

132
00:07:44,560 --> 00:07:47,890
중심 경향, 분산,

133
00:07:47,890 --> 00:07:51,340
그리고 변수 간의 관계와 같은 핵심 아이디어를 탐구했습니다.

134
00:07:51,340 --> 00:07:53,980
지금까지 우리는 변수가 어떻게 연관될 수 있는지 살펴보았습니다--

135
00:07:53,980 --> 00:07:57,470
방향뿐만 아니라 형태와 강도

136
00:07:57,470 --> 00:08:02,050
에 대해서도요.

137
00:08:02,050 --> 00:08:05,950
그런 다음 우리는 그 패턴을 정량화하기 위한 도구로서

138
00:08:05,950 --> 00:08:10,840
상관관계와 공분산으로 넘어갔습니다.

139
00:08:10,840 --> 00:08:14,740
결국 통계학은 단순히 숫자를 계산하는 것이 아닙니다.

140
00:08:14,740 --> 00:08:16,540
불확실성 하에서 결정을 내리는 것이며

141
00:08:16,540 --> 00:08:20,380
신중하고 명확하며 투명한 방식으로 이를 수행하는 것입니다.

142
00:08:20,380 --> 00:08:24,370
다음 강의에서 뵙겠습니다.

