1
00:00:00,000 --> 00:00:04,340
インストラクター：これまでに、単一の変数を分析してきました。

2
00:00:04,340 --> 00:00:06,320
学生の身長です。

3
00:00:06,320 --> 00:00:11,480
このタイプの分析は単変量分析と呼ばれ、

4
00:00:11,480 --> 00:00:15,920
その目的は、記述統計を使用して変数の

5
00:00:15,920 --> 00:00:20,210
特性を説明し、要約することです。

6
00:00:20,210 --> 00:00:24,210
平均、中央値、標準偏差などの、

7
00:00:24,210 --> 00:00:30,530
および視覚化、ヒストグラムや箱ひげ図などのプロットです。

8
00:00:30,530 --> 00:00:35,030
二変量分析では、二つの変数を探り、

9
00:00:35,030 --> 00:00:37,280
それらの関係を調べます。

10
00:00:37,280 --> 00:00:42,710
多変量分析では、三つ以上の変数を

11
00:00:42,710 --> 00:00:46,400
同時に見て、再び理解しようと試みます

12
00:00:46,400 --> 00:00:51,530
それらの、今回はより複雑で、潜在的な関係を。

13
00:00:51,530 --> 00:00:55,160
それでは、学生の身長に関する単変量分析から

14
00:00:55,160 --> 00:00:58,880
二変量分析に移りましょう。これには

15
00:00:58,880 --> 00:01:03,800
身長データに加えて、学生の体重も含まれます。

16
00:01:03,800 --> 00:01:07,270
さて、観察変数が二つになりました。

17
00:01:07,270 --> 00:01:09,420
そして、それらの関係を定量化することは

18
00:01:09,420 --> 00:01:11,290
興味深いことです--

19
00:01:11,290 --> 00:01:15,810
つまり、変数がどのように共変するかを測ることです。

20
00:01:15,810 --> 00:01:19,020
体重と身長は相互に関連しています。

21
00:01:19,020 --> 00:01:23,700
背の高い学生は、背の低い学生よりも重い傾向があります。

22
00:01:23,700 --> 00:01:27,480
それをプロットできます。一つの変数をx軸に

23
00:01:27,480 --> 00:01:30,210
もう一つをy軸にします。

24
00:01:30,210 --> 00:01:33,540
このようなプロットは散布図と呼ばれます。

25
00:01:33,540 --> 00:01:37,980
各点は一人の学生を表しています。

26
00:01:37,980 --> 00:01:40,050
散布図の素晴らしい点は

27
00:01:40,050 --> 00:01:42,970
パターンを視覚化するのを助けることです。

28
00:01:42,970 --> 00:01:46,830
どのように二つの変数が相互に関係しているかです。

29
00:01:46,830 --> 00:01:50,310
図では、左から右へと増加するパターンを観察できます。

30
00:01:50,310 --> 00:01:52,230
これは、体重と身長が正の

31
00:01:52,230 --> 00:01:55,560
相関関係にあることを意味します。

32
00:01:55,560 --> 00:01:58,560
このタイプの関係は、二変量分析においても

33
00:01:58,560 --> 00:02:00,780
関連付けと呼ばれます。

34
00:02:00,780 --> 00:02:05,940
線形関連性は、点がほぼ

35
00:02:05,940 --> 00:02:09,840
まっすぐな線を形成することを意味します。

36
00:02:09,840 --> 00:02:11,230
しかし、非線形の関連性も

37
00:02:11,230 --> 00:02:15,210
観察することができます。

38
00:02:15,210 --> 00:02:18,030
例えば、二次的なパターンなどです。

39
00:02:18,030 --> 00:02:21,150
そして時には明確なパターンがないこともあります、

40
00:02:21,150 --> 00:02:24,150
図に見られるように。

41
00:02:24,150 --> 00:02:27,820
関連性の形に加えて、

42
00:02:27,820 --> 00:02:31,170
我々は方向にも注意を払います。

43
00:02:31,170 --> 00:02:34,540
直線の傾きが上向きであれば、

44
00:02:34,540 --> 00:02:37,530
それは関連性が正であることを意味します。

45
00:02:37,530 --> 00:02:42,360
傾きが下向きであれば、関連性は負です。

46
00:02:42,360 --> 00:02:46,350
また、関連性の強さにも注意を払います。

47
00:02:46,350 --> 00:02:49,860
点が直線の周りにしっかりと集まっていれば、

48
00:02:49,860 --> 00:02:52,890
それは強い関連性です。

49
00:02:52,890 --> 00:02:57,690
点がより散らばっていれば、関連性は弱いです。

50
00:02:57,690 --> 00:03:00,810
重要な点は、強さは

51
00:03:00,810 --> 00:03:03,240
方向に依存しないということです。

52
00:03:03,240 --> 00:03:05,850
強い正の関連性や

53
00:03:05,850 --> 00:03:09,600
強い負の関連性を持つことができます。

54
00:03:09,600 --> 00:03:13,710
また、線形関連性の強さと方向の両方を定量化することもできます。

55
00:03:13,710 --> 00:03:18,290
それは相関係数を使用して行われます、

56
00:03:18,290 --> 00:03:22,270
相関係数はマイナス1から1の間で範囲します。

57
00:03:22,270 --> 00:03:26,090
値が1またはマイナス1に近いほど、

58
00:03:26,090 --> 00:03:29,470
線形関係は強くなります。

59
00:03:29,470 --> 00:03:35,920
ゼロに近い値は、ほとんどまたは全く線形関連性がないことを意味します。

60
00:03:35,920 --> 00:03:43,450
例えば、強い正の相関は約0.9であるかもしれません。

61
00:03:43,450 --> 00:03:46,720
変数が無関係な場合、

62
00:03:46,720 --> 00:03:51,070
0.01のような値を見ることがあります。

63
00:03:51,070 --> 00:03:54,910
ただし、相関は

64
00:03:54,910 --> 00:03:56,950
因果関係を示さないことを心に留めておくべきです。

65
00:03:56,950 --> 00:03:59,440
二つの事象が一緒に動くからといって、

66
00:03:59,440 --> 00:04:03,100
一つが他を引き起こすわけではありません。

67
00:04:03,100 --> 00:04:07,640
たとえ私たちの例において、身長と体重が関連していても、

68
00:04:07,640 --> 00:04:10,960
その関係は直接的な因果関係ではありません。

69
00:04:10,960 --> 00:04:14,380
確かに、相関はありますが、身長は直接的に

70
00:04:14,380 --> 00:04:15,380
体重を引き起こすわけではありません。

71
00:04:15,380 --> 00:04:20,089
代わりに、年齢、栄養、

72
00:04:20,089 --> 00:04:24,110
生物学のような共通の基盤要因が両方に影響を与えています。

73
00:04:24,110 --> 00:04:27,350
共分散を使用して、

74
00:04:27,350 --> 00:04:29,780
二つの変数がともに変動する様子を測定することもできます。

75
00:04:29,780 --> 00:04:32,000
共分散は二つの変数が

76
00:04:32,000 --> 00:04:34,730
共に増加または減少すれば正です。

77
00:04:34,730 --> 00:04:38,840
一方が増加し、もう一方が減少すれば負です。

78
00:04:38,840 --> 00:04:44,900
そして、共分散は一貫したパターンがない場合は0に近くなります。

79
00:04:44,900 --> 00:04:49,310
共分散と相関は、二つの観察セットが

80
00:04:49,310 --> 00:04:52,310
どのように関連しているかを説明する要約統計です。

81
00:04:52,310 --> 00:04:54,170
共分散は関係の方向を示しますが、

82
00:04:54,170 --> 00:04:57,120
強さを有意義な方法で示さず、

83
00:04:57,120 --> 00:05:00,140
相関は線形関係の

84
00:05:00,140 --> 00:05:03,590
方向と強さの両方を定量化するのに役立ちます。

85
00:05:03,590 --> 00:05:08,450
さて、古典的な統計現象について話しましょう。

86
00:05:08,450 --> 00:05:13,580
シンプソンのパラドックスです。

87
00:05:13,580 --> 00:05:16,220
学生の身長に関するデータを収集し、

88
00:05:16,220 --> 00:05:19,430
バスケットボールの得点を取りみてみましょう。

89
00:05:19,430 --> 00:05:24,630
全体のデータを見たとき、

90
00:05:24,630 --> 00:05:27,280
これらの二つの変数が負の

91
00:05:27,280 --> 00:05:31,590
相関関係にあるように見えるかもしれません。

92
00:05:31,590 --> 00:05:32,740
つまり、背の高い学生は得点が少ないようです。

93
00:05:32,740 --> 00:05:38,918
ふむ。

94
00:05:38,918 --> 00:05:40,830
しかし、データを二つのサブグループ、男性と女性に分けると、

95
00:05:40,830 --> 00:05:43,410
それぞれのグループ内で、

96
00:05:43,410 --> 00:05:47,140
背の高い学生は得点が多い傾向があるかもしれません。

97
00:05:47,140 --> 00:05:50,140
したがって、全体のデータは負の相関を示唆していますが、

98
00:05:50,140 --> 00:05:54,060
サブグループデータは正の相関を明らかにします。

99
00:06:01,800 --> 00:06:04,530
両方のグループで。

100
00:06:04,530 --> 00:06:06,900
それはどういう意味ですか？

101
00:06:06,900 --> 00:06:10,680
それは、別の要因、別の変数があることを意味します--

102
00:06:10,680 --> 00:06:12,580
この場合、性別--

103
00:06:12,580 --> 00:06:15,690
が観察された関係に影響を与えるのです。

104
00:06:15,690 --> 00:06:20,250
この変数は混乱変数と呼ばれます。

105
00:06:20,250 --> 00:06:22,770
用語的には、私たちは

106
00:06:22,770 --> 00:06:27,420
身長を独立変数、バスケットボールの得点を

107
00:06:27,420 --> 00:06:30,390
従属変数と呼びます。

108
00:06:30,390 --> 00:06:33,270
したがって、シンプソンの逆説の本質は

109
00:06:33,270 --> 00:06:37,780
この場合、性別のようなサブグループを無視すると、

110
00:06:37,780 --> 00:06:40,900
全体的な傾向が誤解を招く可能性があるということです。

111
00:06:40,900 --> 00:06:43,530
言い換えれば、異なるデータグループに現れる傾向が、

112
00:06:43,530 --> 00:06:48,570
グループが統合されると消えたり逆転したりします。

113
00:06:48,570 --> 00:06:51,840
これは、観察された関係に影響を与える

114
00:06:51,840 --> 00:06:54,030
潜在的または混乱変数によって引き起こされる統計的錯覚です。

115
00:06:54,030 --> 00:06:57,870
この逆説は、相関関係が因果関係を示唆しないという

116
00:06:57,870 --> 00:07:00,540
もう一つの重要な警告です。

117
00:07:00,540 --> 00:07:03,270
さて、これは典型的な

118
00:07:03,270 --> 00:07:07,200
虚偽の相関の例と対比させてください。

119
00:07:07,200 --> 00:07:10,470
アイスクリームの販売とサメの襲撃です。

120
00:07:10,470 --> 00:07:12,430
これら二つの変数には相関があります。

121
00:07:12,430 --> 00:07:15,600
しかし、アイスクリームを食べることがサメの襲撃を引き起こすのですか？

122
00:07:15,600 --> 00:07:18,340
もちろん、そんなことはありません。

123
00:07:18,340 --> 00:07:22,780
本当の説明は第三の要因です。

124
00:07:22,780 --> 00:07:24,480
暑い天候はアイスクリームの販売とビーチの

125
00:07:24,480 --> 00:07:27,360
活動を増加させ、それがサメの襲撃の可能性を高めるのです。

126
00:07:27,360 --> 00:07:31,320
これが、二つの変数が関連しているように見えるが、

127
00:07:31,320 --> 00:07:36,070
実際には外的要因によって引き起こされる虚偽または誤解を招く相関と呼ばれるものです。

128
00:07:36,070 --> 00:07:40,180
今日の講義の要点をまとめると、私たちは

129
00:07:40,180 --> 00:07:44,560
ヒストグラム、ボックスプロット、散布図を使ってデータを視覚化する方法について話しました。

130
00:07:44,560 --> 00:07:47,890
中心傾向、ばらつき、

131
00:07:47,890 --> 00:07:51,340
および変数間の関係といった重要なアイデアを探求しました。

132
00:07:51,340 --> 00:07:53,980
これまで、私たちは変数がいかに関連し得るかを見てきました--

133
00:07:53,980 --> 00:07:57,470
単に方向だけでなく、関係の形態や強さもを含めて。

134
00:07:57,470 --> 00:08:02,050
その後、相関と共分散に進み、

135
00:08:02,050 --> 00:08:05,950
それらのパターンを定量化するためのツールとしての役割を考察しました。

136
00:08:05,950 --> 00:08:10,840
結局、統計は単に数を計算することではありません。

137
00:08:10,840 --> 00:08:14,740
それは、不確実の下で決定を下すことであり、

138
00:08:14,740 --> 00:08:16,540
それを注意深く明確かつ透明な方法で行うことです。

139
00:08:16,540 --> 00:08:20,380
次の講義でお会いしましょう。

