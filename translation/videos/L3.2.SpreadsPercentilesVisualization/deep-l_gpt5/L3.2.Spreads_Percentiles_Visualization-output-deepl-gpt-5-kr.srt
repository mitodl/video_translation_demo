1
00:00:00,000 --> 00:00:04,340
강사: 지금까지는 단일 변수를 분석했습니다,

2
00:00:04,340 --> 00:00:06,320
학생들의 키였습니다.

3
00:00:06,320 --> 00:00:11,480
이러한 분석을 단변량 분석이라고 하며,

4
00:00:11,480 --> 00:00:15,920
변수를 설명하고 요약하는 것을 목표로 합니다

5
00:00:15,920 --> 00:00:20,210
변수의 특성을 기술통계로 설명하고 요약합니다,

6
00:00:20,210 --> 00:00:24,210
예컨대 평균, 중앙값, 표준편차와 같은 지표들입니다,

7
00:00:24,210 --> 00:00:30,530
또 히스토그램, 박스플롯 같은 시각화도 포함합니다.

8
00:00:30,530 --> 00:00:35,030
이변량 분석에서는 두 변수를 탐색하고

9
00:00:35,030 --> 00:00:37,280
그리고 그들 사이의 관계를 살펴봅니다.

10
00:00:37,280 --> 00:00:42,710
그리고 다변량 분석에서는 세 개 이상의 변수를

11
00:00:42,710 --> 00:00:46,400
동시에 살펴봅니다.

12
00:00:46,400 --> 00:00:51,530
이번에는 더 복잡할 수 있는 그들의 관계를 이해하려고 합니다.

13
00:00:51,530 --> 00:00:55,160
그럼 단변량 분석에서

14
00:00:55,160 --> 00:00:58,880
학생들의 키에 대한 단변량 분석에서 이변량 분석으로 넘어가서,

15
00:00:58,880 --> 00:01:03,800
키 데이터에 더해 학생들의 몸무게도 포함해 보겠습니다.

16
00:01:03,800 --> 00:01:07,270
이제 관찰 변수 두 개가 있습니다.

17
00:01:07,270 --> 00:01:09,420
그리고 다음을 정량화해 보는 것이 흥미롭습니다.

18
00:01:09,420 --> 00:01:11,290
두 변수 사이의 관계를—

19
00:01:11,290 --> 00:01:15,810
즉, 두 변수가 함께 어떻게 변하는지 측정하는 것입니다.

20
00:01:15,810 --> 00:01:19,020
몸무게와 키는 서로 관련이 있습니다.

21
00:01:19,020 --> 00:01:23,700
키가 큰 학생일수록 키가 작은 학생보다 몸무게가 더 나가는 경향이 있습니다.

22
00:01:23,700 --> 00:01:27,480
이를 그래프로 나타낼 수 있는데, 한 변수를 x축에

23
00:01:27,480 --> 00:01:30,210
다른 변수를 y축에 두면 됩니다.

24
00:01:30,210 --> 00:01:33,540
이런 그래프를 산점도라고 합니다.

25
00:01:33,540 --> 00:01:37,980
각 점은 학생 한 명을 나타냅니다.

26
00:01:37,980 --> 00:01:40,050
산점도의 큰 장점은

27
00:01:40,050 --> 00:01:42,970
패턴을 파악하는 데 도움이 된다는 점이며,

28
00:01:42,970 --> 00:01:46,830
두 변수가 어떻게 서로 관련되는지를 보여줍니다.

29
00:01:46,830 --> 00:01:50,310
그림에서는 증가하는 패턴을

30
00:01:50,310 --> 00:01:52,230
왼쪽에서 오른쪽으로 관찰할 수 있습니다.

31
00:01:52,230 --> 00:01:55,560
이는 몸무게와 키가

32
00:01:55,560 --> 00:01:58,560
서로 양의 상관관계를 갖는다는 뜻입니다.

33
00:01:58,560 --> 00:02:00,780
이러한 관계는

34
00:02:00,780 --> 00:02:05,940
이변량 분석에서 연관성(association)이라고도 부릅니다.

35
00:02:05,940 --> 00:02:09,840
선형적 연관성은 점들이 대체로

36
00:02:09,840 --> 00:02:11,230
직선 형태를 이루는 것을 의미합니다.

37
00:02:11,230 --> 00:02:15,210
하지만 비선형적 연관성도 관찰될 수 있으며,

38
00:02:15,210 --> 00:02:18,030
예를 들어 이차 곡선 패턴 등이 있습니다.

39
00:02:18,030 --> 00:02:21,150
또 때로는 뚜렷한 패턴이 없을 수도 있습니다,

40
00:02:21,150 --> 00:02:24,150
그림에서 볼 수 있듯이요.

41
00:02:24,150 --> 00:02:27,820
연관성의 형태뿐 아니라

42
00:02:27,820 --> 00:02:31,170
방향도 중요합니다.

43
00:02:31,170 --> 00:02:34,540
선의 기울기가 위쪽을 향하면

44
00:02:34,540 --> 00:02:37,530
양의 연관성을 의미합니다.

45
00:02:37,530 --> 00:02:42,360
기울기가 아래쪽이면 음의 연관성입니다.

46
00:02:42,360 --> 00:02:46,350
연관성의 강도도 중요합니다.

47
00:02:46,350 --> 00:02:49,860
점들이 선 주변에 촘촘히 모여 있으면

48
00:02:49,860 --> 00:02:52,890
강한 연관성입니다.

49
00:02:52,890 --> 00:02:57,690
점들이 더 퍼져 있으면 연관성이 약합니다.

50
00:02:57,690 --> 00:03:00,810
강도는

51
00:03:00,810 --> 00:03:03,240
방향에 의존하지 않는다는 점을 기억해야 합니다.

52
00:03:03,240 --> 00:03:05,850
강한 양의

53
00:03:05,850 --> 00:03:09,600
또는 강한 음의 연관성이 있을 수 있습니다.

54
00:03:09,600 --> 00:03:13,710
연관성의 강도와 방향을

55
00:03:13,710 --> 00:03:18,290
상관계수를 사용해 선형적 연관성의 강도와 방향을 정량화할 수 있습니다,

56
00:03:18,290 --> 00:03:22,270
상관계수는 -1에서 1 사이의 값을 가집니다.

57
00:03:22,270 --> 00:03:26,090
값이 1이나 -1에 가까울수록

58
00:03:26,090 --> 00:03:29,470
선형 관계가 더 강합니다.

59
00:03:29,470 --> 00:03:35,920
0에 가까우면 선형적 연관성이 거의 없다는 뜻입니다.

60
00:03:35,920 --> 00:03:43,450
예를 들어, 강한 양의 상관은 약 0.9 정도일 수 있습니다.

61
00:03:43,450 --> 00:03:46,720
변수들이 관련이 없다면

62
00:03:46,720 --> 00:03:51,070
0.01 같은 값을 볼 수 있습니다.

63
00:03:51,070 --> 00:03:54,910
다만, 상관관계가

64
00:03:54,910 --> 00:03:56,950
인과관계를 의미하지 않는다는 점을 명심해야 합니다.

65
00:03:56,950 --> 00:03:59,440
두 변수가 함께 움직인다고 해서

66
00:03:59,440 --> 00:04:03,100
하나가 다른 하나의 원인이라는 뜻은 아닙니다.

67
00:04:03,100 --> 00:04:07,640
키와 몸무게가 관련되어 있는 우리의 예에서도

68
00:04:07,640 --> 00:04:10,960
그 관계가 직접적인 인과는 아닙니다.

69
00:04:10,960 --> 00:04:14,380
맞습니다, 둘 사이에는 상관이 있지만 키가

70
00:04:14,380 --> 00:04:15,380
체중을 직접 야기하는 것은 아닙니다.

71
00:04:15,380 --> 00:04:20,089
대신 나이, 영양 상태

72
00:04:20,089 --> 00:04:24,110
그리고 생물학적 요인 같은 공통된 기저 요인들이 둘 다에 영향을 미칩니다.

73
00:04:24,110 --> 00:04:27,350
두 변수가 어떻게 함께 변하는지를 측정하는 데

74
00:04:27,350 --> 00:04:29,780
공분산을 사용할 수도 있습니다.

75
00:04:29,780 --> 00:04:32,000
두 변수가

76
00:04:32,000 --> 00:04:34,730
함께 증가하거나 함께 감소하면 공분산은 양수입니다.

77
00:04:34,730 --> 00:04:38,840
한쪽이 증가할 때 다른 쪽이 감소하면 음수입니다.

78
00:04:38,840 --> 00:04:44,900
일관된 패턴이 없으면 공분산은 0에 가깝습니다.

79
00:04:44,900 --> 00:04:49,310
공분산과 상관은 모두

80
00:04:49,310 --> 00:04:52,310
두 관측치 집합이 어떻게

81
00:04:52,310 --> 00:04:54,170
서로 관련되는지를 요약해 주는 통계입니다.

82
00:04:54,170 --> 00:04:57,120
공분산은 관계의 방향을 알려주지만

83
00:04:57,120 --> 00:05:00,140
강도를 의미 있게는 알려주지 못하고,

84
00:05:00,140 --> 00:05:03,590
상관은

85
00:05:03,590 --> 00:05:08,450
선형 관계의 방향과 강도 모두를 정량화하는 데 도움이 됩니다.

86
00:05:08,450 --> 00:05:13,580
이제 고전적인 통계 현상에 대해 이야기해 보겠습니다,

87
00:05:13,580 --> 00:05:16,220
심슨의 역설입니다.

88
00:05:16,220 --> 00:05:19,430
학생들의 키에 관한 데이터를 수집하고

89
00:05:19,430 --> 00:05:24,630
그들이 농구에서 몇 점을 기록하는지에 대한 데이터도 모았다고 가정해 봅시다.

90
00:05:24,630 --> 00:05:27,280
전체 데이터를 보면

91
00:05:27,280 --> 00:05:31,590
두 변수가 음의

92
00:05:31,590 --> 00:05:32,740
상관을 보이는 것처럼 보일 수 있습니다.

93
00:05:32,740 --> 00:05:38,918
즉, 키가 큰 학생일수록 점수를 덜 얻는 것처럼 보입니다.

94
00:05:38,918 --> 00:05:40,830
흠.

95
00:05:40,830 --> 00:05:43,410
하지만 데이터를

96
00:05:43,410 --> 00:05:47,140
남성과 여성 두 하위 집단으로 나누어 보면

97
00:05:47,140 --> 00:05:50,140
각 집단 내에서는

98
00:05:50,140 --> 00:05:54,060
키가 큰 학생이 더 많은 점수를 얻는 경향이 있음을 발견할 수 있습니다.

99
00:05:54,060 --> 00:05:57,880
즉, 전체 데이터는 음의 상관을 시사하지만

100
00:05:57,880 --> 00:06:01,800
하위 집단 데이터는

101
00:06:01,800 --> 00:06:04,530
두 집단 모두에서 양의 상관을 보여줍니다.

102
00:06:04,530 --> 00:06:06,900
이게 무슨 뜻일까요?

103
00:06:06,900 --> 00:06:10,680
이는 또 다른 요인, 다른 변수가

104
00:06:10,680 --> 00:06:12,580
이 경우에는 성별이

105
00:06:12,580 --> 00:06:15,690
관찰된 관계에 영향을 미친다는 뜻입니다.

106
00:06:15,690 --> 00:06:20,250
이런 변수를 교란변수(confounding variable)라고 합니다.

107
00:06:20,250 --> 00:06:22,770
용어상으로는

108
00:06:22,770 --> 00:06:27,420
키를 독립변수, 농구 득점을

109
00:06:27,420 --> 00:06:30,390
종속변수라고 부릅니다.

110
00:06:30,390 --> 00:06:33,270
따라서 심슨의 역설의 핵심은

111
00:06:33,270 --> 00:06:37,780
이처럼 성별과 같은 하위 집단을 무시하면

112
00:06:37,780 --> 00:06:40,900
전체 추세가 오해를 불러일으킬 수 있다는 점입니다.

113
00:06:40,900 --> 00:06:43,530
즉,

114
00:06:43,530 --> 00:06:48,570
각 그룹에서 나타나는 추세가

115
00:06:48,570 --> 00:06:51,840
그룹을 합치면 사라지거나 반대로 나타날 수 있습니다.

116
00:06:51,840 --> 00:06:54,030
이는 통계적 착시로,

117
00:06:54,030 --> 00:06:57,870
관찰된 관계에 영향을 미치는 잠재 변수나 교란변수들에 의해

118
00:06:57,870 --> 00:07:00,540
발생합니다.

119
00:07:00,540 --> 00:07:03,270
이 역설은 우리에게 또 한 번 상기시켜 줍니다

120
00:07:03,270 --> 00:07:07,200
상관관계가 인과관계를 뜻하지 않는다는 사실을요.

121
00:07:07,200 --> 00:07:10,470
이제 이를 고전적인 사례와 비교해 보겠습니다

122
00:07:10,470 --> 00:07:12,430
즉, 가짜 상관관계의 예입니다.

123
00:07:12,430 --> 00:07:15,600
아이스크림 판매량과 상어 공격 건수입니다.

124
00:07:15,600 --> 00:07:18,340
이 두 변수는 상관을 보입니다.

125
00:07:18,340 --> 00:07:22,780
하지만 아이스크림을 먹는 것이 상어 공격을 유발할까요?

126
00:07:22,780 --> 00:07:24,480
물론 아닙니다.

127
00:07:24,480 --> 00:07:27,360
진짜 설명은 제3의 요인입니다.

128
00:07:27,360 --> 00:07:31,320
더운 날씨는 아이스크림 판매와 해변에서의

129
00:07:31,320 --> 00:07:36,070
활동을 모두 증가시키고, 그 결과 상어 공격 가능성도 높입니다.

130
00:07:36,070 --> 00:07:40,180
이처럼

131
00:07:40,180 --> 00:07:44,560
두 변수가 관련되어 보이지만 실제로는

132
00:07:44,560 --> 00:07:47,890
외부 요인에 의해 나타나는 경우를 가짜/오해의 상관관계라고 합니다.

133
00:07:47,890 --> 00:07:51,340
오늘 강의 내용을 정리하면,

134
00:07:51,340 --> 00:07:53,980
데이터를 어떻게 시각화할지

135
00:07:53,980 --> 00:07:57,470
히스토그램, 박스플롯, 산점도로 살펴보았고,

136
00:07:57,470 --> 00:08:02,050
중심경향, 산포 같은 핵심 개념과

137
00:08:02,050 --> 00:08:05,950
변수 간 관계도 탐구했습니다.

138
00:08:05,950 --> 00:08:10,840
지금까지 변수들이 어떻게 연관될 수 있는지—

139
00:08:10,840 --> 00:08:14,740
방향뿐 아니라 형태와 강도까지

140
00:08:14,740 --> 00:08:16,540
살펴보았습니다.

141
00:08:16,540 --> 00:08:20,380
그다음 상관과 공분산으로 넘어가서

142
00:08:20,380 --> 00:08:24,370
그 패턴을 정량화하는 도구로 활용했습니다.

143
00:08:24,370 --> 00:08:28,340
결국 통계는 단순히 숫자를 계산하는 데 그치지 않습니다.

144
00:08:28,340 --> 00:08:31,360
불확실성하에서 의사결정을 내리고

145
00:08:31,360 --> 00:08:36,159
그 과정을 신중하고 명확하며 투명하게 수행하는 것입니다.

146
00:08:36,159 --> 00:08:38,640
다음 강의에서 뵙겠습니다.

