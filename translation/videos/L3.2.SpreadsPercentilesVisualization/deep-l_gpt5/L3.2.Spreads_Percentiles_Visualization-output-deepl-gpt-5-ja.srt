1
00:00:00,000 --> 00:00:04,340
インストラクター：ここまでは単一の変数を分析してきましたが、

2
00:00:04,340 --> 00:00:06,320
生徒の身長です。

3
00:00:06,320 --> 00:00:11,480
この種の分析は単変量解析と呼ばれ、

4
00:00:11,480 --> 00:00:15,920
変数を記述し要約することを目的としており、

5
00:00:15,920 --> 00:00:20,210
記述統計を用いてその特性を示します。

6
00:00:20,210 --> 00:00:24,210
平均、中央値、標準偏差など、

7
00:00:24,210 --> 00:00:30,530
さらにヒストグラムや箱ひげ図といった可視化（プロット）も用います。

8
00:00:30,530 --> 00:00:35,030
二変量解析では、2つの変数と

9
00:00:35,030 --> 00:00:37,280
それらの関係を調べます。

10
00:00:37,280 --> 00:00:42,710
そして多変量解析では、3つ以上の変数を

11
00:00:42,710 --> 00:00:46,400
同時に扱い、

12
00:00:46,400 --> 00:00:51,530
今度はより複雑になり得る関係を理解しようとします。

13
00:00:51,530 --> 00:00:55,160
では、単変量解析から

14
00:00:55,160 --> 00:00:58,880
生徒の身長の分析を二変量解析へ広げましょう。

15
00:00:58,880 --> 00:01:03,800
ここでは身長データに加えて、生徒の体重も含めます。

16
00:01:03,800 --> 00:01:07,270
これで観測変数が2つになりました。

17
00:01:07,270 --> 00:01:09,420
そして、

18
00:01:09,420 --> 00:01:11,290
それらの関係を数値化することは

19
00:01:11,290 --> 00:01:15,810
つまり、変数がどのように共変するかを測定することです。

20
00:01:15,810 --> 00:01:19,020
体重と身長は互いに関係しています。

21
00:01:19,020 --> 00:01:23,700
背の高い生徒は背の低い生徒より体重が重い傾向があります。

22
00:01:23,700 --> 00:01:27,480
それを可視化するには、一方の変数をX軸に、

23
00:01:27,480 --> 00:01:30,210
もう一方をY軸にプロットします。

24
00:01:30,210 --> 00:01:33,540
この種のプロットを散布図と呼びます。

25
00:01:33,540 --> 00:01:37,980
各点は1人の生徒を表します。

26
00:01:37,980 --> 00:01:40,050
散布図の優れている点は、

27
00:01:40,050 --> 00:01:42,970
パターンを見出すのに役立つことです。

28
00:01:42,970 --> 00:01:46,830
2つの変数がどのように関連しているかを示します。

29
00:01:46,830 --> 00:01:50,310
この図では、

30
00:01:50,310 --> 00:01:52,230
左から右へと増加するパターンが観察できます。

31
00:01:52,230 --> 00:01:55,560
これは、体重と身長が

32
00:01:55,560 --> 00:01:58,560
つまり、体重と身長は正の関係にある。

33
00:01:58,560 --> 00:02:00,780
このような関係は、

34
00:02:00,780 --> 00:02:05,940
二変量解析ではアソシエーション（関連）とも呼ばれます。

35
00:02:05,940 --> 00:02:09,840
線形の関連とは、点が多かれ少なかれ

36
00:02:09,840 --> 00:02:11,230
直線状に並ぶことを意味します。

37
00:02:11,230 --> 00:02:15,210
しかし、非線形の関連が

38
00:02:15,210 --> 00:02:18,030
例えば二次的なパターンとして観察されることもあります。

39
00:02:18,030 --> 00:02:21,150
また、明確なパターンが

40
00:02:21,150 --> 00:02:24,150
図のように見られない場合もあります。

41
00:02:24,150 --> 00:02:27,820
関連の形に加えて、

42
00:02:27,820 --> 00:02:31,170
方向性も重要です。

43
00:02:31,170 --> 00:02:34,540
直線の傾きが上向きなら、

44
00:02:34,540 --> 00:02:37,530
正の関連を意味します。

45
00:02:37,530 --> 00:02:42,360
傾きが下向きなら、負の関連です。

46
00:02:42,360 --> 00:02:46,350
さらに、関連の強さも重視します。

47
00:02:46,350 --> 00:02:49,860
点が直線の周りに密に集まっていれば、

48
00:02:49,860 --> 00:02:52,890
強い関連です。

49
00:02:52,890 --> 00:02:57,690
点が広がっていれば、関連は弱いです。

50
00:02:57,690 --> 00:03:00,810
強さは

51
00:03:00,810 --> 00:03:03,240
方向に依存しないことに注意が必要です。

52
00:03:03,240 --> 00:03:05,850
強い正の関連も、

53
00:03:05,850 --> 00:03:09,600
強い負の関連もあり得ます。

54
00:03:09,600 --> 00:03:13,710
また、強さと方向の両方を

55
00:03:13,710 --> 00:03:18,290
相関係数を用いて定量化できます。

56
00:03:18,290 --> 00:03:22,270
相関係数はマイナス1から1の範囲をとります。

57
00:03:22,270 --> 00:03:26,090
値が1またはマイナス1に近いほど、

58
00:03:26,090 --> 00:03:29,470
線形関係は強くなります。

59
00:03:29,470 --> 00:03:35,920
値が0に近い場合は、線形の関連はほとんどないか、全くありません。

60
00:03:35,920 --> 00:03:43,450
例えば、強い正の相関は0.9前後かもしれません。

61
00:03:43,450 --> 00:03:46,720
変数同士が無関係なら、

62
00:03:46,720 --> 00:03:51,070
0.01のような値が得られることもあります。

63
00:03:51,070 --> 00:03:54,910
ただし、相関は

64
00:03:54,910 --> 00:03:56,950
因果関係を意味しないことを忘れてはなりません。

65
00:03:56,950 --> 00:03:59,440
2つの量が一緒に動くからといって、

66
00:03:59,440 --> 00:04:03,100
片方がもう一方の原因であるとは限りません。

67
00:04:03,100 --> 00:04:07,640
身長と体重が関係しているこの例でさえ、

68
00:04:07,640 --> 00:04:10,960
その関係は直接的な因果ではありません。

69
00:04:10,960 --> 00:04:14,380
相関はありますが、身長が直接

70
00:04:14,380 --> 00:04:15,380
体重を引き起こすわけではありません。

71
00:04:15,380 --> 00:04:20,089
その代わりに、年齢や栄養

72
00:04:20,089 --> 00:04:24,110
さらには生物学的要因など、共通の基礎要因が両方に影響します。

73
00:04:24,110 --> 00:04:27,350
また、共分散を用いて、

74
00:04:27,350 --> 00:04:29,780
2つの変数がどのように一緒に変動するかを測定できます。

75
00:04:29,780 --> 00:04:32,000
共分散は、両者が

76
00:04:32,000 --> 00:04:34,730
一緒に増減する場合は正になります。

77
00:04:34,730 --> 00:04:38,840
一方が増え、他方が減る場合は負になります。

78
00:04:38,840 --> 00:04:44,900
一貫したパターンがないときは、共分散は0に近くなります。

79
00:04:44,900 --> 00:04:49,310
共分散も相関も、2つの観測

80
00:04:49,310 --> 00:04:52,310
量がどのように

81
00:04:52,310 --> 00:04:54,170
関連しているかを記述する要約統計量です。

82
00:04:54,170 --> 00:04:57,120
共分散は関係の方向を示しますが、

83
00:04:57,120 --> 00:05:00,140
強さを有意味な尺度では示しません。

84
00:05:00,140 --> 00:05:03,590
これに対して相関は、

85
00:05:03,590 --> 00:05:08,450
線形関係の方向と強さの両方を定量化するのに役立ちます。

86
00:05:08,450 --> 00:05:13,580
さて、古典的な統計現象について話しましょう。

87
00:05:13,580 --> 00:05:16,220
シンプソンのパラドックスです。

88
00:05:16,220 --> 00:05:19,430
例えば、生徒の身長と

89
00:05:19,430 --> 00:05:24,630
バスケットボールでの得点を集めたとします。

90
00:05:24,630 --> 00:05:27,280
全体データを見ると、

91
00:05:27,280 --> 00:05:31,590
これら2つの変数には負の

92
00:05:31,590 --> 00:05:32,740
相関があるように見えるかもしれません。

93
00:05:32,740 --> 00:05:38,918
つまり、背の高い生徒ほど得点が低いように見えます。

94
00:05:38,918 --> 00:05:40,830
ふむ。

95
00:05:40,830 --> 00:05:43,410
しかし、データを

96
00:05:43,410 --> 00:05:47,140
男子と女子の2つのサブグループに分けると、

97
00:05:47,140 --> 00:05:50,140
それぞれのグループ内では、

98
00:05:50,140 --> 00:05:54,060
背の高い生徒ほど得点が高い傾向が見られるかもしれません。

99
00:05:54,060 --> 00:05:57,880
つまり、全体では負の相関が示唆される一方で、

100
00:05:57,880 --> 00:06:01,800
サブグループでは正の相関が

101
00:06:01,800 --> 00:06:04,530
両方のグループで見られるのです。

102
00:06:04,530 --> 00:06:06,900
これは何を意味するのでしょうか。

103
00:06:06,900 --> 00:06:10,680
これは、別の要因、別の変数――

104
00:06:10,680 --> 00:06:12,580
この場合は性別――が

105
00:06:12,580 --> 00:06:15,690
観察された関係に影響しているということです。

106
00:06:15,690 --> 00:06:20,250
この変数は交絡変数と呼ばれます。

107
00:06:20,250 --> 00:06:22,770
用語としては、

108
00:06:22,770 --> 00:06:27,420
身長を独立変数、バスケットボールの得点を

109
00:06:27,420 --> 00:06:30,390
従属変数と呼びます。

110
00:06:30,390 --> 00:06:33,270
つまり、シンプソンのパラドックスの本質は、

111
00:06:33,270 --> 00:06:37,780
この例のように性別といったサブグループを無視すると、

112
00:06:37,780 --> 00:06:40,900
全体の傾向が誤解を招く可能性があるという点です。

113
00:06:40,900 --> 00:06:43,530
言い換えれば、別々のグループでは見られる傾向が、

114
00:06:43,530 --> 00:06:48,570
グループを統合すると、

115
00:06:48,570 --> 00:06:51,840
消えたり逆転したりするのです。

116
00:06:51,840 --> 00:06:54,030
これは、潜在する、あるいは交絡する変数によって

117
00:06:54,030 --> 00:06:57,870
観察された関係が影響を受けることで生じる

118
00:06:57,870 --> 00:07:00,540
統計的な錯覚です。

119
00:07:00,540 --> 00:07:03,270
このパラドックスは、

120
00:07:03,270 --> 00:07:07,200
相関は因果を意味しないという重要な教訓の一つでもあります。

121
00:07:07,200 --> 00:07:10,470
では、古典的な

122
00:07:10,470 --> 00:07:12,430
偽相関の例と対比してみましょう。

123
00:07:12,430 --> 00:07:15,600
アイスクリームの売上とサメの襲撃です。

124
00:07:15,600 --> 00:07:18,340
これら2つの変数には相関があります。

125
00:07:18,340 --> 00:07:22,780
しかし、アイスクリームを食べることがサメの襲撃を引き起こすのでしょうか。

126
00:07:22,780 --> 00:07:24,480
もちろん違います。

127
00:07:24,480 --> 00:07:27,360
実際の説明は第3の要因です。

128
00:07:27,360 --> 00:07:31,320
暑い天候はアイスクリームの売上と

129
00:07:31,320 --> 00:07:36,070
海での活動の双方を増やし、その結果サメの襲撃の可能性が高まります。

130
00:07:36,070 --> 00:07:40,180
このように、

131
00:07:40,180 --> 00:07:44,560
2つの変数が関連しているように見えても、その結びつきが実際には

132
00:07:44,560 --> 00:07:47,890
外的要因に左右されている場合を、偽相関（誤解を招く相関）と呼びます。

133
00:07:47,890 --> 00:07:51,340
さて、今日の講義をまとめると、

134
00:07:51,340 --> 00:07:53,980
データを可視化する方法として、

135
00:07:53,980 --> 00:07:57,470
ヒストグラム、箱ひげ図、散布図を取り上げ、

136
00:07:57,470 --> 00:08:02,050
中心傾向や散らばりといった重要な概念、

137
00:08:02,050 --> 00:08:05,950
そして変数間の関係についても検討しました。

138
00:08:05,950 --> 00:08:10,840
ここまで、変数同士がどのように関連し得るか――

139
00:08:10,840 --> 00:08:14,740
方向性だけでなく、形や強さについても

140
00:08:14,740 --> 00:08:16,540
見てきました。

141
00:08:16,540 --> 00:08:20,380
その後、相関と共分散へと進み、

142
00:08:20,380 --> 00:08:24,370
それらのパターンを定量化するための道具として扱いました。

143
00:08:24,370 --> 00:08:28,340
結局のところ、統計は単に数を計算することではありません。

144
00:08:28,340 --> 00:08:31,360
不確実性のもとで意思決定を行い、

145
00:08:31,360 --> 00:08:36,159
それを慎重に、明確に、透明性をもって進めることなのです。

146
00:08:36,159 --> 00:08:38,640
次回の講義でお会いしましょう。

